---
title: "maxent model avec xvalidation (year-based test training)"
author: "Samantha Andrews"
output: html_notebook
---

# Overview
A note to anyone who might happen to stumble across this... I am a beginner in R and have had no exposure to similar languages. I don't know what I'm doing. The code herein is unlikely to be elegant and there area probably more efficient ways of running the code.

Built with 'r getRversion()'..

# Package dependencies
You can install and load them using the following code which uses a function called [ipak](https://gist.github.com/stevenworthington/3178163). Note this function checks to see if the packages are installed first before loading.


```{r pre-install & load packages, include=FALSE}
gc() 
options (java.parameters = "-Xmx6g")
packages <- c("rJava", "dismo", "stringr", "raster", "ecospat", "enmSdm", "plyr", "data.table", "RColorBrewer")
source("../src/ipak.R")
ipak(packages)
```


#load the presence-background dataset 
("../output/bio/presab_nafo_yr.csv")

```{r load pres-background dataset}
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)
colnames(presback)
```

this dataset contains a lot of columns you don't need for the maxent models. Remove them here

```{r remove unnecessary columns}
prback <- subset(presback, select = -c(cell_id, id, decimalLatitude, decimalLongitude, datecollected, institutioncode, individualcount, depth, resname, originalscientificname, collectioncode, day, nafo_zone, gear, longitude_meters, latitude_meters, total_cell_obs_xy, total_cell_obs_xyt, bottom_depth, XXtotal_cell_obs_xyzt, temp_celsius_depth, temp_celsius_surface, longitude_meters.1, latitude_meters.1, bottom_depth_glorys, longitude_meters.2, latitude_meters.2, cell_id_3d, total_cell_obs_xyzt, cell_id_xyzt, depthlayerno, depth_layer))
colnames(presback)
```

#monthly model data selection and prep
For each monthly model, subset the data to the month you want, and the variables you want (Based on spearmans and VIF)

```{r}
allvar <- c("occurrence", "year", "month", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
prback <- subset(prback, select = c(allvar))
colnames(prback)
```




now each month contains NAs - lets remove these (maxent principle doesnt allow for missing data - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.5607&rep=rep1&type=pdf)

```{r remove na vals}
prback <- na.omit(prback)
#prback <- subset(prback, month == 8)
presyrs <-  subset(prback, occurrence == 1) #this is to get years with complete presence data 
presyrs <- unique(presyrs$year) #make a vector of unique years
prback <- prback[prback$year %in% presyrs, ] #keep only the data for which there is precence years
```

```{r}
# train <- prback
# trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
# train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
# timeslice <- "all_data"
# betavallist <- 0.25
# mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/", timeslice, "/models"), args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", "betamultiplier=0.25"))
```


normal model..
mod12 <- maxent(x = prab, p = pa, file = .asc, args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE")) 
mod12

```{r train and test inc AIC for reg val}
aicetc <- read.csv("../data/env/AICcCalculations.csv", header = TRUE) #pre-created csv file
betavallist <- seq(1.75, 4, by = 0.25)

timeslice <- "all_data"
train <- prback
trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
train  <- subset(train, select = -c(year, occurrence, month)) #don't need year and occurrence for modelling
nfolds <- cbind(c(1:5))

  
 for (h in 1:length(betavallist)){
   betamval <-  betavallist[h]
    #betamval <-  0.5
    mod <- maxent(x = train, p = trainpa, plots = FALSE, path = paste0("../output/maxent/", timeslice, "/models"), args=c("maximumiterations=5000", "responsecurves=FALSE", "jackknife=FALSE", "plots=FALSE", "threads=8", "addsamplestobackground=TRUE", paste0("replicates=", nrow(nfolds)), "replicatetype=crossvalidate", paste0("betamultiplier=", betamval))) 

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code
    
    #count number of non-zero coefficients, excluding the final four rows
    lambdas_list <- list.files(paste0("../output/maxent/", timeslice, "/models/"), pattern = "*lambdas", full.names = TRUE)
    samppred_list <- list.files(paste0("../output/maxent/", timeslice, "/models/"), pattern = "*samplePredictions.csv", full.names = TRUE)
    
          #no presences used in model (less those used for testing)

    maxresults <- read.csv(paste0("../output/maxent/", timeslice, "/models/maxentResults.csv"), header = TRUE)

for (i in 1:nrow(aicetc)){   
for(f in 1:nrow(nfolds)){
    modn <- nfolds[f]-1
      lamf <- lambdas_list[f]
      sampf <- samppred_list[f]
      coefile <- read.csv(paste0(lamf), header = FALSE, stringsAsFactors=FALSE)
      coefile <- head(coefile, -4)
      coefile2 <- subset(coefile, V2 != 0)
      nocoeff <- nrow(coefile2)
      bick <- sum(as.numeric(coefile2[, 2])) #dodgy 
      bic <- (bick*log(sum(trainpa == 1)) - 2*11) #dodgy
      #natural log
      samplepred <- read.csv(paste0(sampf), header = TRUE)
      samplepred$nat_log <- log(samplepred$Raw.prediction)
      sumsamplepred <- sum(samplepred$nat_log)
   
      
      notrainingpoints <- maxresults$X.Training.samples[f]
      testauc <- maxresults$Test.AUC[f]
      trainauc <- maxresults$Training.AUC[f]
      modno <- maxresults$Species[f]
    

   if(aicetc$nfold[i] == modn){
      aicetc$Train_AUC[i] <- trainauc
      aicetc$Test_AUC[i] <- testauc
      aicetc$n[i] <- notrainingpoints
      aicetc$coefficients[i] <- nocoeff
      aicetc$sum.of.logs[i] <- sumsamplepred
  
      aicetc$bic[i] <- bic #not sure this is correct...
      aicetc$beta[i] <- betamval
      aicetc$foldno[i] <- modn

    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum[i] <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
    
    aicetc$AIC[i] <- ((2*aicetc$coefficients[i])-(2*aicetc$sum.of.logs[i]))
    aicetc$AICc[i] <- (-2*(aicetc$sum.of.logs[i])+((2*aicetc$coefficients[i])*(aicetc$n[i]/(aicetc$n[i] - aicetc$coefficients[i]-1))))
   }
    
  }
    write.csv(aicetc, paste0("../output/maxent/", timeslice, "/models/", "_", betamval, "_AICforMaxentReg.csv"), row.names = FALSE)

}
  }
 
    aicperbetalst <- list.files(paste0("../output/maxent/", timeslice, "/models/"), pattern = paste0(".*AICforMaxentReg.csv"), full.names = TRUE)
    for (beta in 1:length(aicperbetalst)){
      aic <- read.csv(aicperbetalst[beta])
      bval <- str_sub(aicperbetalst[beta], 35, -20) #the beta value
      aicmean <- colwise(mean)(aic)
      write.csv(aicmean, paste0("../output/maxent/", timeslice, "/models/aic_mean_", bval, ".csv"), row.names = FALSE)
    }
    
    aicmeanlst <- list.files(paste0("../output/maxent/", timeslice, "/models/"), pattern = paste0("^aic_mean"), full.names = TRUE)
    bavg <- lapply(aicmeanlst, read.csv, header = TRUE)
    bavg <- do.call(rbind, bavg)
    write.csv(bavg, paste0("../output/maxent/", timeslice, "/models/avgbetalst.csv"), row.names = FALSE)


```

#model selection

lowest aicc is 0.25

```{r final models plus predict}

aicetc <- read.csv("../data/env/AICcCalculations.csv", header = TRUE) #pre-created csv file
betaval <-  0.25

timeslice <- "all_data"
train <- prback
trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
train  <- subset(train, select = -c(year, occurrence, month)) #don't need year and occurrence for modelling
nfolds <- cbind(c(1:5))


mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/all_data/models"), args=c("writebackgroundpredictions=TRUE", "maximumiterations=5000", "threads=8", "addsamplestobackground=TRUE", paste0("replicates=", nrow(nfolds)), "replicatetype=crossvalidate", paste0("betamultiplier=", betaval)))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code


  #count number of non-zero coefficients, excluding the final four rows
    lambdas_list <- list.files(paste0("../output/maxent/", timeslice, "/models/"), pattern = "*lambdas", full.names = TRUE)
    samppred_list <- list.files(paste0("../output/maxent/", timeslice, "/models/"), pattern = "*samplePredictions.csv", full.names = TRUE)
    
          #no presences used in model (less those used for testing)

    maxresults <- read.csv(paste0("../output/maxent/", timeslice, "/models/maxentResults.csv"), header = TRUE)

for (i in 1:nrow(aicetc)){   
for(f in 1:nrow(nfolds)){
    modn <- nfolds[f]-1
      lamf <- lambdas_list[f]
      sampf <- samppred_list[f]
      coefile <- read.csv(paste0(lamf), header = FALSE, stringsAsFactors=FALSE)
      coefile <- head(coefile, -4)
      coefile2 <- subset(coefile, V2 != 0)
      nocoeff <- nrow(coefile2)
      bick <- sum(as.numeric(coefile2[, 2])) #dodgy 
      bic <- (bick*log(sum(trainpa == 1)) - 2*11) #dodgy
      
  #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2]))
    bic <- (bick*log(sum(trainpa == 1)) - 2*11)
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
    #continuous boyce index
    predPres <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    predBg <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_backgroundPredictions.csv"), header = TRUE)
    predPres <- predPres$Cloglog.prediction
    predBg <- predBg$Cloglog
    cbi <- contBoyce(pres = predPres, bg = predBg)
    
  
      aicetc$train_AUC <- trainauc #training only AUC - not tested
      aicetc$no_trainng_points <- notrainingpoints #numberof points used for training
      aicetc$coefficients <- nocoeff #this is to calculate the AIC
      aicetc$sum.of.logs <- sumsamplepred #this is to calculate the AIC
      aicetc$test_AUC <- evauc #testing AUC
      aicetc$test_evcor <- evcor #testing correlation coefficient
      aicetc$test_evpcor <- evpcor # testing p-value for correlation coefficient
      aicetc$test_nopresence <- evnp 
      aicetc$test_nobackground <- evna
      aicetc$test_maxsumsenspec <- evmaxtprtnr
      aicetc$test_maxkap <- evmaxkap
      aicetc$test_no_omission <- evno_omission
      aicetc$test_prevalence <- evprevalence
      aicetc$test_equal_sens_spec <- evequal_sens_spec
      aicetc$test_sensitivity <- evsensitivity
      aicetc$tss <- max(ev@TPR + ev@TNR) - 1
      aicetc$test_bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      aicetc$cbi <- cbi
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$no_trainng_points/(aicetc$no_trainng_points - aicetc$coefficients-1))))
    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
    aicetc$mpa_0.9_clog <- ecospat.mpa(samplepred$Cloglog.prediction, perc = 0.9) #90%
    aicetc$year <- yr

}
}
    
    write.csv(aicetc, paste0("../output/maxent/", timeslice, "/models/", "_", betaval, "_AICforMaxentReg.csv"), row.names = FALSE)

    saveRDS(mod, file = "../output/maxent/all_data/maxmod.rds", ascii = FALSE, version = NULL, compress = TRUE, refhook = NULL)
    
```
    
```{r final models predict}
mod <- readRDS(file = "../output/maxent/all_data/maxmod.rds", refhook = NULL)
px <- response(mod@models[[4]])

filenames <- list.files("../data/all_data_layers/", pattern="*.csv", full.names=TRUE)
unlayer_yrX <- rbindlist(lapply(filenames,fread))
unlayer_yrX <- unlayer_yrX[complete.cases(unlayer_yrX), ]
aea <- raster("../output/env/aea.tif") 
unlayer_yr <- subset(unlayer_yrX, ascmonths == "11")

   for (td in 1:nrow(unlayer_yr)){
temp_depth <- raster(unlayer_yr$temp_depth[td])
      crs(temp_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(temp_depth) <- "temp_depth"
      temp_depth <- projectRaster(temp_depth, aea)
      chl_surface <- raster(unlayer_yr$chl_surface[td])
      crs(chl_surface) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(chl_surface) <- "chl_surface"
      chl_surface <- projectRaster(chl_surface, aea)
      o2_depth <- raster(unlayer_yr$o2_depth[td])
      crs(o2_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(o2_depth) <- "o2_depth"
      o2_depth <- projectRaster(o2_depth, aea)
      salinity_depth <- raster(unlayer_yr$salinity_depth[td])
      crs(salinity_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(salinity_depth) <- "salinity_depth"
      salinity_depth <- projectRaster(salinity_depth, aea)
      nao_sample <- raster(unlayer_yr$nao_sample[td])
      crs(nao_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_sample) <- "nao_sample"
      nao_sample <- projectRaster(nao_sample, aea)
      nao_prev <- raster(unlayer_yr$nao_prev[td])
      crs(nao_prev) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_prev) <- "nao_prev"
      nao_prev <- projectRaster(nao_prev, aea)
      nao_winter <- raster(unlayer_yr$nao_winter[td])
      crs(nao_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(nao_winter) <- "nao_winter"
      nao_winter <- projectRaster(nao_winter, aea)
      amo_sample <- raster(unlayer_yr$amo_sample[td])
      crs(amo_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(amo_sample) <- "amo_sample"
      amo_sample <- projectRaster(amo_sample, aea)
      amo_winter <- raster(unlayer_yr$amo_winter[td])
      crs(amo_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(amo_winter) <- "amo_winter"
      amo_winter <- projectRaster(amo_winter, aea)
      stackn <- unlayer_yr$stackname[td]
      stack <- stack(temp_depth, salinity_depth, o2_depth, chl_surface, nao_sample, nao_prev, nao_winter, amo_sample, amo_winter)

      #stackSave(test,unlayer_yr$stackname[td])
      pred <- predict(mod, stack, file = paste0("../output/maxent/all_data/predictions/nov/", "cloglog_", stackn, ".asc"), overwrite=TRUE, args='outputformat=cloglog') 
      #prplot <- plot(pred, png(paste0("../output/maxent/all_data/predictions/", "cloglog_", stackn, ".png")))
      #dev.off() # stops automatic saving of the plot to a png
     
    }
#}

```

#model averageing

ok! now to average results:

- the AICforMaxentReg.csv 
- the maxentResults.csv
- the asc files per depth layer

open all maxentReg files




for this bit may need to stack rasters by depth... this will need some working with the name
get unique filenames into a list
ignore the first X characters in the filename (yr_mthna_) and stack based on the last bit of the filename
then do something probably with raster package

```{r avg asc layers cloglog}
stdep <- read.csv("../output/maxent/all_data/stackdepthlist.csv", header = TRUE)
asc_list <- list.files(paste0("../output/maxent/all_data/predictions/nov"), pattern = "cloglog.*.asc", full.names = TRUE)
depthlayers <- data.frame(cbind(unique(stdep$ascdepths)))
names(depthlayers)[names(depthlayers) == "cbind.unique.stdep.ascdepths.."] <- "depth"
depthlayers$depth <- as.character(depthlayers$depth)

colno <- 1

for (d in 1:nrow(depthlayers)){
  dep <- depthlayers$depth[d]
  for (a in 1:length(asc_list)){
    asc <- asc_list[a]
    if (grepl(dep, asc)){
      depthlayers[d , paste0("a", colno)] <- asc
      colno <- colno+1
    }
  }
}
write.csv(depthlayers, ("../output/maxent/all_data/predictions/nov/cloglog_asclayerbydepth.csv"), row.names = FALSE)

#depthlayers <- read.csv("../output/maxent/all_data/predictions/cloglog_asclayerbydepth.csv", header = FALSE)

for (x in 1:nrow(depthlayers)){
  dstack <- stack()
  asclay <- depthlayers[x, ]
  asclay <- asclay[!is.na(asclay)]
  dep <- as.character(asclay[1])
  asclay <- as.data.frame(rbind(asclay))
  asclay[1] <- NULL
  for (ly in 1:length(asclay)){
    lay <- as.character(asclay[ ,40])
    layr <- raster(lay)
    dstack <- stack(dstack, layr)
    if(ly == length(asclay)){
      stavg <- calc(dstack, fun = mean, na.rm = TRUE)
      writeRaster(stavg, (paste0("../output/maxent/all_data/predictions/nov/avg_", dep, ".asc")), overwrite=TRUE)
      avgplot <- plot(stavg, png(paste0("../output/maxent/all_data/predictions/nov/avg_", dep, ".png")))
      while (!is.null(dev.list()))  dev.off()
    }
  }
}  
  




```


```{r binary maps on averaged depth layer}
#calculate minimal predicted area using ecospat

samplepred1 <- read.csv(paste0("../output/maxent/all_data/models/species_1_samplePredictions.csv"), header = TRUE)
mpa_thr1 <- ecospat.mpa(samplepred1$Cloglog.prediction, perc = 0.9) #90%
samplepred2 <- read.csv(paste0("../output/maxent/all_data/models/species_2_samplePredictions.csv"), header = TRUE)
mpa_thr2 <- ecospat.mpa(samplepred2$Cloglog.prediction, perc = 0.9) #90%
samplepred3 <- read.csv(paste0("../output/maxent/all_data/models/species_3_samplePredictions.csv"), header = TRUE)
mpa_thr3 <- ecospat.mpa(samplepred3$Cloglog.prediction, perc = 0.9) #90%
samplepred4 <- read.csv(paste0("../output/maxent/all_data/models/species_4_samplePredictions.csv"), header = TRUE)
mpa_thr4 <- ecospat.mpa(samplepred4$Cloglog.prediction, perc = 0.9) #90%
samplepred5 <- read.csv(paste0("../output/maxent/all_data/models/species_0_samplePredictions.csv"), header = TRUE)
mpa_thr5 <- ecospat.mpa(samplepred5$Cloglog.prediction, perc = 0.9) #90%
mpa_avg <- mean(mpa_thr1, mpa_thr2, mpa_thr3, mpa_thr4, mpa_thr5)


#binary threshold function
binmpa <- function(x) {
  ifelse(x <  mpa_thr, 0,
  ifelse(x >=  mpa_thr, 1, NA))
  }

clogasc_list <- list.files(paste0("../output/maxent/all_data/predictions/"), pattern = "^avg_.*.asc", full.names = TRUE)

mpa_thr <- mpa_avg
for (cum in 1:length(clogasc_list)){
  cumascyr <- str_sub(clogasc_list[46], start = 43) #selects the year from the file name
  cumascyr <- str_sub(cumascyr, end = -4) #selects the year from the file name
  cumasc <- raster(clogasc_list[cum])
  ascname <- names(cumasc)
  cum_mpathr <- calc(cumasc, fun = binmpa)
  writeRaster(cum_mpathr, paste0("../output/maxent/all_data/predictions/binary_mpa_", ascname, ".asc"), overwrite = TRUE)
  plot(cum_mpathr, png(paste0("../output/maxent/all_data/predictions/binary_mpa_", ascname, ".png")), overwrite = TRUE)
  dev.off() # stops automatic saving of the plot to a png
  }



```

```{r binary map averaged 2D representation}

binaryclog_list <- list.files(paste0("../output/maxent/all_data/predictions/"), pattern = "^binary_mpa_avg_.*.asc", full.names = TRUE)

binstack <- stack(binaryclog_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/all_data/predictions/binary_avg_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/all_data/predictions/binary_avg_2d.png")))
dev.off()




```


add land to plots with standard legend (working code) THIS WORK!!!
```{r}
aea <- raster("../output/env/aea.tif") #the correct CRS
<<<<<<< HEAD
maplst <- list.files("../output/maxent/all_data/predictions/apr", pattern = "binary_avg_2d.*.asc", full.names = TRUE)
s <- shapefile("../data/env/landp/landpro.shp") #made in arcgis
apr <- aea@crs
brk <- seq(0.1, 1, 0.1) #for legend
=======
maplst <- list.files("../output/maxent/all_data/predictions/", pattern = "binary_avg_2d.*.asc", full.names = TRUE)
s <- shapefile("../data/env/landp/landpro.shp") #made in arcgis
apr <- aea@crs
#brk <- seq(0.1, 1, 0.1) #for legend
>>>>>>> 92478b1c7a7358e853cdb53667dd57f7dd1c8c0f
redtrans <- rgb(218, 215, 216, 90, maxColorValue=255) 
outsidemcp <- shapefile("../data/env/landp/mcpout.shp") #made in arcgis

r <- raster(maplst[1])
plot(pras)

for (pred in 1:length(maplst)){
<<<<<<< HEAD
  pras <- raster("../output/maxent/all_data/predictions/apr/avg_47.2119.asc")
  crs(pras) <- apr
  ascname <- names(pras)
  #pras[pras >0] <- 1
  lp <- plot(pras, breaks=brk, col=rev(colorRampPalette(brewer.pal(10, "Spectral"))(10)), axes = FALSE, box = FALSE, legend = TRUE)
=======
  pras <- raster(maplst[pred])
  crs(pras) <- apr
  ascname <- names(pras)
  pras[pras >0] <- 1
  lp <- plot(pras, breaks=brk, col=rev(colorRampPalette(brewer.pal(10, "Spectral"))(10)), axes = FALSE, box = FALSE, legend = FALSE)
>>>>>>> 92478b1c7a7358e853cdb53667dd57f7dd1c8c0f
  lp <- plot(pras)
  lp <- plot(outsidemcp,  col = redtrans, border = redtrans, add = TRUE)
  lp <- plot(s, col = "#474646", border = "#474646", add = TRUE)
  print(lp)
<<<<<<< HEAD
 # dev.copy(png, (paste0("../output/maxent/all_data/predictions/", ascname, pred, ".png")), width = 1920,height = 1080)
  #dev.off() # stops automatic saving of the plot to a png))
=======
  dev.copy(png, (paste0("../output/maxent/all_data/predictions/", ascname, pred, ".png")), width = 1920,height = 1080)
  dev.off() # stops automatic saving of the plot to a png))
>>>>>>> 92478b1c7a7358e853cdb53667dd57f7dd1c8c0f
}

```


```{r habitat classification on probability - high only}


#binary threshold function
binprob <- function(x){
  ifelse(x >= 0.8, 1,
  ifelse(x < 0.8, 0, NA)) 
}

clogasc_list <- list.files(paste0("../output/maxent/all_data/predictions/july/"), pattern = "^avg_.*.asc", full.names = TRUE)

for (cum in 1:length(clogasc_list)){
  cumascdep <- str_sub(clogasc_list[cum], start = 47, end = -5) #selects the depth from the file name
  cumasc <- raster(clogasc_list[cum])
  ascname <- names(cumasc)
  cum_mpathr <- calc(cumasc, fun = binprob)
  writeRaster(cum_mpathr, paste0("../output/maxent/all_data/predictions/july/binary_p80_", cumascdep, ".asc"), overwrite = TRUE)
  plot(cum_mpathr, png(paste0("../output/maxent/all_data/predictions/july/binary_p80_", cumascdep, ".png")), overwrite = TRUE)
  dev.off() # stops automatic saving of the plot to a png
  }

```



```{r binary map averaged 2D representation p80}

binaryclog_list <- list.files(paste0("../output/maxent/all_data/predictions/july/"), pattern = "^binary_p80.*.asc", full.names = TRUE)

binstack <- stack(binaryclog_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/all_data/predictions/july/bin_p80_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/all_data/predictions/july/bin_avg_p80_2d.png")))
dev.off()

```


```{r}
aea <- raster("../output/env/aea.tif") #the correct CRS
maplst <- list.files("../output/maxent/all_data/predictions/", pattern = "binary_avg_2d.*.asc", full.names = TRUE)
s <- shapefile("../data/env/landp/landpro.shp") #made in arcgis
apr <- aea@crs
#brk <- seq(0.1, 1, 0.1) #for legend
redtrans <- rgb(218, 215, 216, 90, maxColorValue=255) 
outsidemcp <- shapefile("../data/env/landp/mcpout.shp") #made in arcgis
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)
pronly <- subset(presback, occurrence == 1)
prjul <- subset(pronly, month == 7)
prjan <- subset(pronly, month == 1)


  pras <- raster("../output/maxent/predictions/jul/binary_highavg_2d.asc")
  crs(pras) <- apr
  ascname <- names(pras)
  pras[pras >0] <- 1
  #lp <- plot(pras, col=rev(colorRampPalette(brewer.pal(10, "Spectral"))(10)), axes = FALSE, box = FALSE, legend = FALSE)
  lp <- plot(pras, axes = FALSE, box = FALSE, legend = FALSE)
  lp <- plot(outsidemcp,  col = redtrans, border = redtrans, add = TRUE)
  lp <- plot(s, col = "#474646", border = "#474646", add = TRUE)
  lp <- points(prjul$longitude_meters, prjul$latitude_meters, add = TRUE)
  print(lp)
  dev.copy(png, ("../output/maxent/all_data/predictions/july/oldmod_p80_2d_july.png"), width = 1920,height = 1080)
  dev.off() # stops automatic saving of the plot to a png))
```

```{r}
       #continuous boyce index 
for(f in 1:nrow(nfolds)){
  fold <- (f - 1)
  predPres <- read.csv(paste0("../output/maxent/all_data/models/species_", fold,  "_samplePredictions.csv"), header = TRUE)
  predBg <- read.csv(paste0("../output/maxent/all_data/models/species_", fold, "_backgroundPredictions.csv"), header = TRUE)
  predPres <- predPres$Cloglog.prediction
  predBg <- predBg$Cloglog
  cbi <- contBoyce(pres = predPres, bg = predBg)
  write.csv(cbi, paste0("../output/maxent/all_data/cbi_", fold, ".csv"))
  
}
```



