---
title: "maxent model avec xvalidation (year-based test training)"
author: "Samantha Andrews"
output: html_notebook
---

# Overview
A note to anyone who might happen to stumble across this... I am a beginner in R and have had no exposure to similar languages. I don't know what I'm doing. The code herein is unlikely to be elegant and there area probably more efficient ways of running the code.

Built with 'r getRversion()'..

# Package dependencies
You can install and load them using the following code which uses a function called [ipak](https://gist.github.com/stevenworthington/3178163). Note this function checks to see if the packages are installed first before loading.


```{r pre-install & load packages, include=FALSE}
options(java.parameters = "-Xmx1g" )#needs to run before dismo loaded - boosts memory for java to 1g
packages <- c("dismo", "stringr", "rJava", "raster", "ecospat")
source("../src/ipak.R")
ipak(packages)
```


#load the presence-background dataset 
("../output/bio/presab_nafo_yr.csv")

```{r load pres-background dataset}
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)

#remove unnecessary columns for maxent
presback <- subset(presback, select = -c(cell_id, id, decimalLatitude, decimalLongitude, datecollected, institutioncode, individualcount, depth, resname, originalscientificname, collectioncode, day, nafo_zone, gear, longitude_meters, latitude_meters, total_cell_obs_xy, total_cell_obs_xyt, bottom_depth, XXtotal_cell_obs_xyzt, temp_celsius_depth, temp_celsius_surface, longitude_meters.1, latitude_meters.1, bottom_depth_glorys, longitude_meters.2, latitude_meters.2, cell_id_3d, total_cell_obs_xyzt, cell_id_xyzt))
colnames(presback)
```

this dataset contains a lot of columns you don't need for the maxent models. Remove them here


#monthly model data selection and prep
For each monthly model, subset the data to the month you want, and the variables you want (Based on spearmans and VIF)

```{r}
janvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface")
marvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
aprvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
mayvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
junvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
julvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
augvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
sepvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
octvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
novvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
decvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")

mthnavar_lst <- list(jan = janvar, mar = marvar, apr = aprvar, may = mayvar, jun = junvar, jul = julvar, aug = augvar, sep = sepvar, oct = octvar, nov = novvar, dec = decvar)
```

select mont
```{r month of interest -change}
mthna <- "jan"
mthno <- "1"
```



```{r subsest data by month}
prback <- subset(presback, month == mthno)
prback <- subset(prback, select = mthnavar_lst[[mthna]])
```

now each month contains NAs - lets remove these (maxent principle doesnt allow for missing data - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.5607&rep=rep1&type=pdf)

```{r remove na vals}
prback <- na.omit(prback)
```


normal model..
mod12 <- maxent(x = prab, p = pa, file = .asc, args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", "replicates=5", "replicatetype=crossvalidate")) 
mod12

```{r train and test inc AIC for reg val}
modelmonth <- cbind(paste0(mthna ,unique(prback$year)))
aicetc <- read.csv("../data/env/AICcCalculations.csv", header = TRUE) #pre-created csv file
betavallist <- cbind(aicetc$regularization)
nfolds <- 5

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year == yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  
  for (h in 1:nrow(betavallist)){
    betamval <-  betavallist[h]
    mod <- maxent(x = train, p = trainpa, args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("replicates=", nfolds), "replicatetype=crossvalidate", paste0("betamultiplier=", betavallist[h])), path = paste0("C:/Users/bunny/Documents/GitHub/Chapter_1/output/maxent/p2/models/", timeslice)) #here the full path is needed

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code
    

    #count number of non-zero coefficients, excluding the final four rows
    lambdas_list <- list.files(paste0("../output/maxent/p2/models/", timeslice), pattern = "*lambdas", full.names = TRUE)
    samppred_list <- list.files(paste0("../output/maxent/p2/models/", timeslice), pattern = "*samplePredictions.csv", full.names = TRUE)
    for(fold in 1:nfolds){
      fn <- fold
      modn <- fn-1
      lamf <- lambdas_list[fold]
      sampf <- samppred_list[fold]
      coefile <- read.csv(paste0(lamf), header = FALSE, stringsAsFactors=FALSE)
      coefile <- head(coefile, -4)
      coefile2 <- subset(coefile, V2 != 0)
      nocoeff <- nrow(coefile2)
      bick <- sum(as.numeric(coefile2[, 2])) #dodgy 
      bic <- (bick*log(sum(trainpa == 1)) - 2*11) #dodgy
      #natural log
      samplepred <- read.csv(paste0(sampf), header = TRUE)
      samplepred$nat_log <- log(samplepred$Raw.prediction)
      sumsamplepred <- sum(samplepred$nat_log)
      
      maxresults <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)

      
      #no presences used in model (less those used for testing)

      notrainingpoints <- maxresults$X.Training.samples[fold]
      testauc <- maxresults$Test.AUC[fold]
      trainauc <- maxresults$Training.AUC[fold]
      modno <- maxresults$Species[fold]
    
    
 
    
    
  
  
   #test auc scores and other lovely things you might want to include
   # ev <- evaluate(p = testp, a= testb, model = mod)
    #evauc <- ev@auc
    #evcor <- ev@cor
    #evpcor <- ev@pcor
    #evnp <- ev@np
    #evna <- ev@na
    #evmaxtprtnr <- threshold(ev, 'spec_sens')
    #evmaxkap <- threshold(ev, 'kappa')
    #evno_omission <- threshold(ev, 'no_omission')
    #evprevalence <- threshold(ev, 'prevalence')
    #evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    #evsensitivity <- threshold(ev, 'sensitivity')
    
  
      aicetc$train_AUC <- trainauc
      aicetc$test_AIC <- testauc
      aicetc$no_trainng_points <- notrainingpoints
      aicetc$test_coefficients <- nocoeff
      aicetc$test_sum.of.logs <- sumsamplepred
      #aicetc$test_AUC <- evauc
      #aicetc$test_evcor <- evcor
      # aicetc$test_evpcor <- evpcor
      # aicetc$test_nopresence <- evnp
      # aicetc$test_nobackground <- evna
      # aicetc$test_maxsumsenspec <- evmaxtprtnr
      # aicetc$test_maxkap <- evmaxkap
      # aicetc$test_no_omission <- evno_omission
      # aicetc$test_prevalence <- evprevalence
      # aicetc$test_equal_sens_spec <- evequal_sens_spec
      # aicetc$test_sensitivity <- evsensitivity
      aicetc$test_bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$n/(aicetc$n - aicetc$coefficients-1))))
    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
    }
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$n/(aicetc$n - aicetc$coefficients-1))))
write.csv(aicetc, paste0("../output/maxent/p2/models/", timeslice, "/", modn, "AICforMaxentReg.csv"), row.names = FALSE)

    }
  


}




```

#model selection
next step... select the models you want for each year and run those models again (primarily based on lowest AICc but check test AUC and other things too)

KEEP A NOTE OF THESE IN ONENOTE

y1998 = 2.75
y1999 = 2.25
y2000 = 2
y2001 = 1.75
y2002 = 2
y2003 = 2
y2004 = 2
y2005 = 2.25
y2006 = 1.75
y2007 = 1.75
y2008 = 2.25
y2009 = 2.25
y2010 = 2.5
y2011 =  2.5


```{r final models plus predict}
modelmonth <- cbind(paste0(mthna, unique(prback$year)))
aicetc <- read.csv("../data/env/AICcFinalmod.csv", header = TRUE) #pre-created csv file
unlayer <- read.csv(paste0("../data/env/asc_layerlist", mthna, ".csv"), header = TRUE) #if code doesnt work put back to unlayer_yr

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(prback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling

  
  if (timeslice == "y2001" | timeslice == "y2006" | timeslice == "y2007"){
    betaval <- 1.75
  } else if (timeslice == "y2000"| timeslice == "y2002" | timeslice == "y2003" | timeslice == "y2004"){
    betaval <- 2
  } else if (timeslice == "y1999" | timeslice == "y2005" | timeslice == "y2008" | timeslice == "y2009"){
    betaval <- 2.25
  } else if (timeslice == "y2010" | timeslice == "y2011"){
    betaval <- 2.5
  } else if (timeslice == "y1998"){
    betaval <- 2.75
  }
  
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/p2/models/", timeslice), args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betaval)))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2]))
    bic <- (bick*log(sum(trainpa == 1)) - 2*11)
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
  
      aicetc$train_AUC <- trainauc
      aicetc$no_trainng_points <- notrainingpoints
      aicetc$test_coefficients <- nocoeff
      aicetc$test_sum.of.logs <- sumsamplepred
      aicetc$test_AUC <- evauc
      aicetc$test_evcor <- evcor
      aicetc$test_evpcor <- evpcor
      aicetc$test_nopresence <- evnp
      aicetc$test_nobackground <- evna
      aicetc$test_maxsumsenspec <- evmaxtprtnr
      aicetc$test_maxkap <- evmaxkap
      aicetc$test_no_omission <- evno_omission
      aicetc$test_prevalence <- evprevalence
      aicetc$test_equal_sens_spec <- evequal_sens_spec
      aicetc$test_sensitivity <- evsensitivity
      aicetc$test_bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$n/(aicetc$n - aicetc$coefficients-1))))
    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%

    write.csv(aicetc, paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)


    unlayer_yr <- subset(unlayer, ascyears == yr)
    unlayer_yr <- unlayer_yr[-c(1), ]
    unlayer_yr[] <- lapply(unlayer_yr, as.character) #from https://stackoverflow.com/questions/2851015/convert-data-frame-columns-from-factors-to-characters
    stackdeplst <- list()
    stackdep <- subset(unlayer_yr, select = c(stackname, ascdepths))
    stackdeplst[[year]] <- stackdep
    #write.csv(stackdep, paste0("../output/maxent/p2/predictions/stackdepthlist_", yr, ".csv"), row.names = FALSE)
    aea <- raster("../output/env/aea.tif") 

    for (td in 1:nrow(unlayer_yr)){
      temp_depth <- raster(unlayer_yr$temp_depth[td])
      crs(temp_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(temp_depth) <- "temp_depth"
      temp_depth <- projectRaster(temp_depth, aea)
      chl_surface <- raster(unlayer_yr$chl_surface[td])
      crs(chl_surface) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(chl_surface) <- "chl_surface"
      chl_surface <- projectRaster(chl_surface, aea)
      o2_depth <- raster(unlayer_yr$o2_depth[td])
      crs(o2_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(o2_depth) <- "o2_depth"
      o2_depth <- projectRaster(o2_depth, aea)
      salinity_depth <- raster(unlayer_yr$salinity_depth[td])
      crs(salinity_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(salinity_depth) <- "salinity_depth"
      salinity_depth <- projectRaster(salinity_depth, aea)
      nao_sample <- raster(unlayer_yr$nao_sample[td])
      crs(nao_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_sample) <- "nao_sample"
      nao_sample <- projectRaster(nao_sample, aea)
      nao_prev <- raster(unlayer_yr$nao_prev[td])
      crs(nao_prev) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_prev) <- "nao_prev"
      nao_prev <- projectRaster(nao_prev, aea)
      nao_winter <- raster(unlayer_yr$nao_winter[td])
      crs(nao_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(nao_winter) <- "nao_winter"
      nao_winter <- projectRaster(nao_winter, aea)
      amo_sample <- raster(unlayer_yr$amo_sample[td])
      crs(amo_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(amo_sample) <- "amo_sample"
      amo_sample <- projectRaster(amo_sample, aea)
      amo_winter <- raster(unlayer_yr$amo_winter[td])
      crs(amo_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(amo_winter) <- "amo_winter"
      amo_winter <- projectRaster(amo_winter, aea)
      stackn <- unlayer_yr$stackname[td]
      stack <- stack(temp_depth, salinity_depth, o2_depth, chl_surface, nao_sample, nao_prev, nao_winter, amo_sample, amo_winter)
      #stackSave(test,unlayer_yr$stackname[td])
      pred <- predict(mod, stack, file = paste0("../output/maxent/p2/predictions/", mthna, "/", "cloglog_", stackn, ".asc"), overwrite=TRUE, args='outputformat=cloglog') 
      predcum <- predict(mod, stack, file = paste0("../output/maxent/p2/predictions/", mthna, "/", "cumu_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=Cumulative')) 
      prplot <- plot(pred, png(paste0("../output/maxent/p2/predictions/", mthna, "/", "cloglog_", stackn, ".png")))
      dev.off() # stops automatic saving of the plot to a png
      prplotcum <- plot(predcum, png(paste0("../output/maxent/p2/predictions/", mthna, "/", "cumu_", stackn, ".png"))) 
      dev.off() # stops automatic saving of the plot to a png
    }
}

stdep <- do.call(rbind, stackdeplst)
write.csv(stdep, paste0("../output/maxent/p2/predictions/", mthna, "/stack_depth.csv"), row.names = FALSE)
```

#model averageing

ok! now to average results:

- the AICforMaxentReg.csv 
- the maxentResults.csv
- the asc files per depth layer

open all maxentReg files

```{r avg maxentReg}

for (i in 1:length(modelmonth)){
  timeslice <- modelmonth[i]
  yr <- str_sub(timeslice, -4) #the year being used for testing
  if(yr == 1998){
    aic1998 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr1998 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 1999){
    aic1999 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr1999 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2000){
    aic2000 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2000 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2001){
    aic2001 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2001 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2002){
    aic2002 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2002 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2003){
    aic2003 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2003 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2004){
    aic2004 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2004 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2005){
    aic2005 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2005 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2006){
    aic2006 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2006 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2007){
    aic2007 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2007 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2008){
    aic2008 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2008 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2009){
    aic2009 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2009 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2010){
    aic2010 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2010 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2011){
    aic2011 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2011 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2012){
    aic2012 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2012 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2013){
    aic2013 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2013 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2014){
    aic2014 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2014 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2015){
    aic2015 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2015 <- read.csv(paste0("../output/maxent/p2/models/", timeslice, "/maxentResults.csv"), header = TRUE)
  }
}

aic <- rbind(aic1998, aic1999, aic2000, aic2001, aic2002, aic2003, aic2004, aic2005, aic2006, aic2007, aic2008, aic2009, aic2010, aic2011)
maxr <- rbind(maxr1998, maxr1999, maxr2000, maxr2001, maxr2002, maxr2003, maxr2004, maxr2005, maxr2006, maxr2007, maxr2008, maxr2009, maxr2010, maxr2011)

aicm <- colMeans(aic)
aicm$mod <- "avg"
avgAIC <- rbind(aic, aicm)

maxr$Species <- 1
maxrm <- colMeans(maxr)
maxrm$Species <- "avg"
maxrm <- rbind(maxr, maxrm)

write.csv(avgAIC, paste0("../output/maxent/p2/models/", mthna, "avgAIC.csv"), row.names = FALSE)
write.csv(maxrm, paste0("../output/maxent/p2/models/", mthna, "avgmaxentresults.csv"), row.names = FALSE)
```


for this bit may need to stack rasters by depth... this will need some working with the name
get unique filenames into a list
ignore the first X characters in the filename (yr_mthna_) and stack based on the last bit of the filename
then do something probably with raster package

```{r avg asc layers cloglog}
asc_list <- list.files(paste0("../output/maxent/p2/predictions/", mthna), pattern = "cloglog*.asc", full.names = TRUE)
depthlayers <- data.frame(cbind(unique(stdep$ascdepths)))
names(depthlayers)[names(depthlayers) == "cbind.unique.stdep.ascdepths.."] <- "depth"
depthlayers$depth <- as.character(depthlayers$depth)

colno <- 1

for (d in 1:nrow(depthlayers)){
  dep <- depthlayers$depth[d]
  for (a in 1:length(asc_list)){
    asc <- asc_list[a]
    if (grepl(dep, asc)){
      depthlayers[d , paste0("a", colno)] <- asc
        colno <- colno+1
    }
  }
}
write.csv(depthlayers, (paste0("../output/maxent/p2/predictions/", mthna, "/cloglog_asclayerbydepth.csv")), row.names = TRUE)


for (x in 1:nrow(depthlayers)){
  asclay <- depthlayers[x, ]
  asclay <- asclay[!is.na(asclay)]
  asclay <- as.data.frame(rbind(asclay))
  asclay$V1 <- as.character(asclay$V1) #v1 corresponds to depth
  asclay$V2 <- as.character(asclay$V2) #v2 to end corresponds to year
  asclay$V3 <- as.character(asclay$V3)
  asclay$V4 <- as.character(asclay$V4)
  asclay$V5 <- as.character(asclay$V5)
  asclay$V6 <- as.character(asclay$V6)
  asclay$V7 <- as.character(asclay$V7)
  asclay$V8 <- as.character(asclay$V8)
  asclay$V9 <- as.character(asclay$V9)
  asclay$V10 <- as.character(asclay$V10)
  asclay$V11 <- as.character(asclay$V11)
  asclay$V12 <- as.character(asclay$V12)
  asclay$V13 <- as.character(asclay$V13)
  asclay$V14 <- as.character(asclay$V14)
  asclay$V15 <- as.character(asclay$V15)  
  
  asclaydep <- asclay$V1
  
  asc1998 <- raster(asclay$V2)
  asc1999 <- raster(asclay$V3)
  asc2000 <- raster(asclay$V4)
  asc2001 <- raster(asclay$V5)
  asc2002 <- raster(asclay$V6)
  asc2003 <- raster(asclay$V7)
  asc2004 <- raster(asclay$V8)
  asc2005 <- raster(asclay$V9)
  asc2006 <- raster(asclay$V10)
  asc2007 <- raster(asclay$V11)
  asc2008 <- raster(asclay$V12)
  asc2009 <- raster(asclay$V13)
  asc2010 <- raster(asclay$V14)
  asc2011 <- raster(asclay$V15)

  stkasc <- stack(asc1998, asc1999, asc2000, asc2001, asc2002, asc2003, asc2004, asc2005, asc2006, asc2007, asc2008, asc2009, asc2010, asc2011)
  avg <- calc(stkasc, fun = mean)
  
  writeRaster(avg, (paste0("../output/maxent/p2/predictions/", mthna, "/avg_", asclaydep, ".asc")), overwrite=TRUE, args='outputformat=cloglog')
  avgplot <- plot(avg, png(paste0("../output/maxent/p2/predictions/", mthna, "/avg_", asclaydep, ".png"))) 
  dev.off()
}


ascdepth_list <- list.files(paste0("../output/maxent/p2/predictions/", mthna), glob2rx(pattern = "avg_*.asc"), full.names = TRUE)


clog_asc120  <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_120.asc"))
clog_asc41.18 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_41.18.asc"))
clog_asc1.55586 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_1.55586.asc"))
clog_asc1045.85 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_1045.85.asc"))
clog_asc108.03 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_108.03.asc"))
clog_asc11.7737 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_11.7737.asc"))
clog_asc1151.99 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_1151.99.asc"))
clog_asc1265.86 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_1265.86.asc"))
clog_asc13.991 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_13.991.asc"))
clog_asc133.076 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_133.076.asc"))
clog_asc1387.38 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_1387.38.asc"))
clog_asc147.406 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_147.406.asc"))
clog_asc16.5253 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_16.5253.asc"))
clog_asc163.165 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_163.165.asc"))
clog_asc180.55 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_180.55.asc"))
clog_asc19.4298 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_19.4298.asc"))
clog_asc199.79 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_199.79.asc"))
clog_asc2.66768 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_2.66768.asc"))
clog_asc22.7576 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_22.7576.asc"))
clog_asc221.141 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_221.141.asc"))
clog_asc244.891 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_244.891.asc"))
clog_asc26.5583 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_26.5583.asc"))
clog_asc271.356 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_271.356.asc"))
clog_asc3.85628 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_3.85628.asc"))
clog_asc30.8746 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_30.8746.asc"))
clog_asc300.888 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_300.888.asc"))
clog_asc333.863 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_333.863.asc"))
clog_asc35.7402 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_35.7402.asc"))
clog_asc370.689 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_370.689.asc"))
clog_asc411.794 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_411.794.asc"))
clog_asc457.626 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_457.626.asc"))
clog_asc47.2119 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_47.2119.asc"))
clog_asc5.14036 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_5.14036.asc"))
clog_asc508.64 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_508.64.asc"))
clog_asc53.8506 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_53.8506.asc"))
clog_asc565.292 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_565.292.asc"))
clog_asc6.54303 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_6.54303.asc"))
clog_asc61.1128 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_61.1128.asc"))
clog_asc628.026 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_628.026.asc"))
clog_asc69.0217 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_69.0217.asc"))
clog_asc697.259 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_697.259.asc"))
clog_asc77.6112 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_77.6112.asc"))
clog_asc773.368 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_773.368.asc"))
clog_asc8.09252 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_8.09252.asc"))
clog_asc856.679 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_856.679.asc"))
clog_asc86.9294 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_86.9294.asc"))
clog_asc9.82275 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_9.82275.asc"))
clog_asc947.448 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_947.448.asc"))
clog_asc97.0413 <- raster(paste0("../output/maxent/p2/predictions/", mthna, "/avg_97.0413.asc"))

stackavg <- stack(clog_asc120, clog_asc41.18, clog_asc1.55586, clog_asc1045.85, clog_asc108.03, clog_asc11.7737, clog_asc1151.99, clog_asc1265.86, clog_asc13.991, clog_asc133.076, clog_asc1387.38, clog_asc147.406, clog_asc16.5253, clog_asc163.165, clog_asc180.55, clog_asc19.4298, clog_asc199.79, clog_asc2.66768, clog_asc22.7576, clog_asc221.141, clog_asc244.891, clog_asc26.5583, clog_asc271.356, clog_asc3.85628, clog_asc30.8746, clog_asc300.888, clog_asc333.863, clog_asc35.7402, clog_asc370.689, clog_asc411.794, clog_asc457.626, clog_asc47.2119, clog_asc5.14036, clog_asc508.64, clog_asc53.8506, clog_asc565.292, clog_asc6.54303, clog_asc61.1128, clog_asc628.026, clog_asc69.0217, clog_asc697.259, clog_asc77.6112, clog_asc773.368, clog_asc8.09252, clog_asc856.679, clog_asc86.9294, clog_asc9.82275, clog_asc947.448, clog_asc97.0413)

stsum <- sum(stackavg, na.rm = TRUE)
  writeRaster(stsum, (paste0("../output/maxent/p2/predictions/", mthna, "/clog_sum_", mthna, ".asc")), overwrite=TRUE)
  sumplot <- plot(stsum, png(paste0("../output/maxent/p2/predictions/", mthna, "/clog_sum_", mthna, ".png"))) 
  dev.off()
stavg <- calc(stackavg, fun = mean, na.rm = TRUE)
  writeRaster(stavg, (paste0("../output/maxent/p2/predictions/", mthna, "/clog_avg_", mthna, ".asc")), overwrite=TRUE)
  avgplot <- plot(stavg, png(paste0("../output/maxent/p2/predictions/", mthna, "/clog_avg_", mthna, ".png"))) 
  dev.off()

```









asc120
asc41.18
asc1.55586
asc1045.85
asc108.03
asc11.7737
asc1151.99
asc1265.86
asc13.991
asc133.076
asc1387.38
asc147.406
asc16.5253
asc163.165
asc180.55
asc19.4298
asc199.79
asc2.66768
asc22.7576
asc221.141
asc244.891
asc26.5583
asc271.356
asc3.85628
asc30.8746
asc300.888
asc333.863
asc35.7402
asc370.689
asc411.794
asc457.626
asc47.2119
asc5.14036
asc508.64
asc53.8506
asc565.292
asc6.54303
asc61.1128
asc628.026
asc69.0217
asc697.259
asc77.6112
asc773.368
asc8.09252
asc856.679
asc86.9294
asc9.82275
asc947.448
asc97.0413


