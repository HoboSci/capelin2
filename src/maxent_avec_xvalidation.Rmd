---
title: "maxent model avec xvalidation (year-based test training)"
author: "Samantha Andrews"
output: html_notebook
---

# Overview
A note to anyone who might happen to stumble across this... I am a beginner in R and have had no exposure to similar languages. I don't know what I'm doing. The code herein is unlikely to be elegant and there area probably more efficient ways of running the code.

Built with 'r getRversion()'..

# Package dependencies
You can install and load them using the following code which uses a function called [ipak](https://gist.github.com/stevenworthington/3178163). Note this function checks to see if the packages are installed first before loading.


```{r pre-install & load packages, include=FALSE}
options(java.parameters = "-Xmx2g" )#needs to run before dismo loaded - boosts memory for java to 1g
packages <- c("dismo", "stringr", "rJava", "raster", "ecospat", "bossMaps", "lattice", "tidyr", "enmSdm", "ggplot2", "plyr", "reshape2")
source("../src/ipak.R")
ipak(packages)
```


#load the presence-background dataset 
("../output/bio/presab_nafo_yr.csv")

```{r load pres-background dataset}
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)
colnames(presback)
```

this dataset contains a lot of columns you don't need for the maxent models. Remove them here

```{r remove unnecessary columns}
presback <- subset(presback, select = -c(cell_id, id, decimalLatitude, decimalLongitude, datecollected, institutioncode, individualcount, depth, resname, originalscientificname, collectioncode, day, nafo_zone, gear, longitude_meters, latitude_meters, total_cell_obs_xy, total_cell_obs_xyt, bottom_depth, XXtotal_cell_obs_xyzt, temp_celsius_depth, temp_celsius_surface, longitude_meters.1, latitude_meters.1, bottom_depth_glorys, longitude_meters.2, latitude_meters.2, cell_id_3d, total_cell_obs_xyzt, cell_id_xyzt))
colnames(presback)
```

#monthly model data selection and prep
For each monthly model, subset the data to the month you want, and the variables you want (Based on spearmans and VIF)

```{r}
janvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_winter")
marvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
aprvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
mayvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
junvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
julvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
augvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
sepvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
octvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
novvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
decvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")

mthnavar_lst <- list(jan = janvar, mar = marvar, apr = aprvar, may = mayvar, jun = junvar, jul = julvar, aug = augvar, sep = sepvar, oct = octvar, nov = novvar, dec = decvar)
```

select month
```{r month of interest -change}
mthna <- "oct"
mthno <- "10"
```



```{r subsest data by month}
prback <- subset(presback, month == mthno)
prback <- subset(prback, select = mthnavar_lst[[mthna]])
```

now each month contains NAs - lets remove these (maxent principle doesnt allow for missing data - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.5607&rep=rep1&type=pdf)

note will need to reajust background points too as some years may no longer have presence data

```{r remove na vals}
prback <- na.omit(prback)
presyrs <-  subset(prback, occurrence == 1) #this is to get years with complete presence data 
presyrs <- unique(presyrs$year) #make a vector of unique years
prback <- prback[prback$year %in% presyrs, ] #keep only the data for which there is precence years

```


normal model..
mod12 <- maxent(x = prab, p = pa, file = .asc, args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE")) 
mod12

```{r train and test inc AIC for reg val}
presyrs <-  #this is to get years with complete presence data 
  

modelmonth <- cbind(paste0(mthna ,unique(prback$year)))
aicetc <- read.csv("../data/env/AICcCalculations.csv", header = TRUE) #pre-created csv file
betavallist <- cbind(aicetc$regularization)

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(prback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  
  for (h in 1:nrow(betavallist)){
    betaval <-  betavallist[h]
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/", timeslice), args=c('plots=FALSE', "maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betavallist[h])))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2])) #dodgy 
    bic <- (bick*log(sum(trainpa == 1)) - 2*11) #dodgy
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
   #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
    for (i in 1:nrow(aicetc)){
    if(aicetc$regularization[i] == betaval){
      aicetc$train_AUC[i] <- trainauc
      aicetc$no_trainng_points[i] <- notrainingpoints
      aicetc$coefficients[i] <- nocoeff
      aicetc$sum.of.logs[i] <- sumsamplepred
      aicetc$test_AUC[i] <- evauc
      aicetc$test_evcor[i] <- evcor
      aicetc$test_evpcor[i] <- evpcor
      aicetc$test_nopresence[i] <- evnp
      aicetc$test_nobackground[i] <- evna
      aicetc$test_maxsumsenspec[i] <- evmaxtprtnr
      aicetc$test_maxkap[i] <- evmaxkap
      aicetc$test_no_omission[i] <- evno_omission
      aicetc$test_prevalence[i] <- evprevalence
      aicetc$test_equal_sens_spec[i] <- evequal_sens_spec
      aicetc$test_sensitivity[i] <- evsensitivity
      aicetc$test_bic[i] <- bic #not sure this is correct...
      aicetc$beta[i] <- betaval
      #calculate minimal predicted area using ecospat
      aicetc$mpa_0.9_cum[i] <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
      
    aicetc$AIC[i] <- ((2*aicetc$coefficients[i])-(2*aicetc$sum.of.logs[i]))
    aicetc$AICc[i] <- (-2*(aicetc$sum.of.logs[i])+((2*aicetc$coefficients[i])*(aicetc$no_trainng_points[i]/(aicetc$no_trainng_points[i] - aicetc$coefficients[i]-1))))
    }
   }
  }
  

write.csv(aicetc, paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)

}  
  

```

#model selection
next step... select the models you want for each year and run those models again (primarily based on lowest AICc but check test AUC and other things too)

you need to go through each aic file manually....



KEEP A NOTE OF THESE IN ONENOTE

#run final model
```{r final models plus predict}
modelmonth <- cbind(paste0(mthna, unique(prback$year)))
aicetc <- read.csv("../data/env/AICcFinalmod.csv", header = TRUE) #pre-created csv file
unlayer <- read.csv(paste0("../data/env/asc_layerlist", mthna, ".csv"), header = TRUE) #if code doesnt work put back to unlayer_yr

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(prback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  #mess_pr <- subset(train, occurrence == 1)
  #mess_pr  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling

  
  if (yr == "1998"){
    betaval <- 0.25
  } else if (yr == "2001"){
    betaval <- 0.75
  } else if (yr == "2002" | yr == "2003"| yr == "2004"| yr == "2006"| yr == "2011"){
    betaval <- 1
  } else if (yr == "2005"){
    betaval <- 1.25
  } else if (yr == "1999" | yr == "2000"| yr == "2009"){
    betaval <- 1.5
  } else if (yr == "2007"){
    betaval <- 1.75
  } else if (yr == "2010"){
    betaval <- 2
  } else if (yr == "2008"){
    betaval <- 2.25
  }

  
  
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/", timeslice), args=c("writebackgroundpredictions=TRUE",  "maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betaval)))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2]))
    bic <- (bick*log(sum(trainpa == 1)) - 2*11)
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
    #continuous boyce index
    predPres <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    predBg <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_backgroundPredictions.csv"), header = TRUE)
    predPres <- predPres$Cloglog.prediction
    predBg <- predBg$Cloglog
    cbi <- contBoyce(pres = predPres, bg = predBg)
    
  
      aicetc$train_AUC <- trainauc #training only AUC - not tested
      aicetc$no_trainng_points <- notrainingpoints #numberof points used for training
      aicetc$coefficients <- nocoeff #this is to calculate the AIC
      aicetc$sum.of.logs <- sumsamplepred #this is to calculate the AIC
      aicetc$test_AUC <- evauc #testing AUC
      aicetc$test_evcor <- evcor #testing correlation coefficient
      aicetc$test_evpcor <- evpcor # testing p-value for correlation coefficient
      aicetc$test_nopresence <- evnp 
      aicetc$test_nobackground <- evna
      aicetc$test_maxsumsenspec <- evmaxtprtnr
      aicetc$test_maxkap <- evmaxkap
      aicetc$test_no_omission <- evno_omission
      aicetc$test_prevalence <- evprevalence
      aicetc$test_equal_sens_spec <- evequal_sens_spec
      aicetc$test_sensitivity <- evsensitivity
      aicetc$tss <- max(ev@TPR + ev@TNR) - 1
      aicetc$test_bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      aicetc$cbi <- cbi
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$no_trainng_points/(aicetc$no_trainng_points - aicetc$coefficients-1))))
    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
    aicetc$mpa_0.9_clog <- ecospat.mpa(samplepred$Cloglog.prediction, perc = 0.9) #90%
    aicetc$year <- yr


    write.csv(aicetc, paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)


    unlayer_yr <- subset(unlayer, ascyears == yr)
    unlayer_yr <- unlayer_yr[-c(1), ]
    unlayer_yr[] <- lapply(unlayer_yr, as.character) #from https://stackoverflow.com/questions/2851015/convert-data-frame-columns-from-factors-to-characters
    stackdeplst <- list()
    stackdep <- subset(unlayer_yr, select = c(stackname, ascdepths))
    stackdeplst[[year]] <- stackdep
    write.csv(stackdep, paste0("../output/maxent/models/", timeslice, "/stackdepthlist_", yr, ".csv"), row.names = FALSE)
    aea <- raster("../output/env/aea.tif") 

   for (td in 1:nrow(unlayer_yr)){
      temp_depth <- raster(unlayer_yr$temp_depth[td])
      crs(temp_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(temp_depth) <- "temp_depth"
      temp_depth <- projectRaster(temp_depth, aea)
      chl_surface <- raster(unlayer_yr$chl_surface[td])
      crs(chl_surface) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(chl_surface) <- "chl_surface"
      chl_surface <- projectRaster(chl_surface, aea)
      o2_depth <- raster(unlayer_yr$o2_depth[td])
      crs(o2_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(o2_depth) <- "o2_depth"
      o2_depth <- projectRaster(o2_depth, aea)
      salinity_depth <- raster(unlayer_yr$salinity_depth[td])
      crs(salinity_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(salinity_depth) <- "salinity_depth"
      salinity_depth <- projectRaster(salinity_depth, aea)
      nao_sample <- raster(unlayer_yr$nao_sample[td])
      crs(nao_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_sample) <- "nao_sample"
      nao_sample <- projectRaster(nao_sample, aea)
      nao_prev <- raster(unlayer_yr$nao_prev[td])
      crs(nao_prev) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_prev) <- "nao_prev"
      nao_prev <- projectRaster(nao_prev, aea)
      nao_winter <- raster(unlayer_yr$nao_winter[td])
      crs(nao_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(nao_winter) <- "nao_winter"
      nao_winter <- projectRaster(nao_winter, aea)
      amo_sample <- raster(unlayer_yr$amo_sample[td])
      crs(amo_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(amo_sample) <- "amo_sample"
      amo_sample <- projectRaster(amo_sample, aea)
      amo_winter <- raster(unlayer_yr$amo_winter[td])
      crs(amo_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(amo_winter) <- "amo_winter"
      amo_winter <- projectRaster(amo_winter, aea)
      stackn <- unlayer_yr$stackname[td]
      stack <- stack(temp_depth, salinity_depth, o2_depth, chl_surface, nao_sample, nao_prev, nao_winter, amo_sample, amo_winter)


      #stackSave(test,unlayer_yr$stackname[td])
      pred <- predict(mod, stack, file = paste0("../output/maxent/predictions/", mthna, "/", "cloglog_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=cloglog')) 
      predraw <- predict(mod, stack, file = paste0("../output/maxent/predictions/", mthna, "/", "raw_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=raw')) 
      prplot <- plot(pred, png(paste0("../output/maxent/predictions/", mthna, "/", "cloglog_", stackn, ".png")))
      dev.off() # stops automatic saving of the plot to a png
     
      #mess
      
      #messev <- dismo::mess(x = stack, v = mess_pr, full = FALSE)
      #messplot <- plot(messev, png(paste0("../output/maxent/predictions/", mthna, "/", "mess_", stackn, ".png")))
      #dev.off()
      # not working how i'd like....
    }
}

stdep <- do.call(rbind, stackdeplst)
write.csv(stdep, paste0("../output/maxent/models/", timeslice, "/stack_depth.csv"), row.names = FALSE)
```

```{r avg maxentReg}

for (i in 1:length(modelmonth)){
  timeslice <- modelmonth[i]
  yr <- str_sub(timeslice, -4) #the year being used for testing
  if(yr == 1998){
    aic1998 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr1998 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 1999){
    aic1999 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr1999 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2000){
    aic2000 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2000 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2001){
    aic2001 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2001 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2002){
    aic2002 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2002 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2003){
    aic2003 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2003 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2004){
    aic2004 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2004 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2005){
    aic2005 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2005 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2006){
    aic2006 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2006 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2007){
    aic2007 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2007 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2008){
    aic2008 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2008 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2009){
    aic2009 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2009 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2010){
    aic2010 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2010 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2011){
    aic2011 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2011 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2012){
    aic2012 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2012 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2013){
    aic2013 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2013 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2014){
    aic2014 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2014 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2015){
    aic2015 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2015 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
  }
}

aic <- rbind(aic1998, aic1999, aic2000, aic2001, aic2002, aic2003, aic2004, aic2005, aic2006, aic2007, aic2008, aic2009, aic2010, aic2011)
maxr <- rbind(maxr1998, maxr1999, maxr2000, maxr2001, maxr2002, maxr2003, maxr2004, maxr2005, maxr2006, maxr2007, maxr2008, maxr2009, maxr2010, maxr2011)


aicm <- colMeans(aic)
aicm$mod <- "avg"
avgAIC <- rbind(aic, aicm)

maxr$Species <- 1
maxrm <- colMeans(maxr)
maxrm$Species <- "avg"
maxrm <- rbind(maxr, maxrm)

write.csv(avgAIC, paste0("../output/maxent/models/", mthna, "avgAIC.csv"), row.names = FALSE)
write.csv(maxrm, paste0("../output/maxent/models/", mthna, "avgmaxentresults.csv"), row.names = FALSE)
```

summary table of average maxent results for each month
```{r average AIC etc for each month in one table}
aic_lst <- list.files("../output/maxent/models/", pattern = "avgAIC.csv", full.names = TRUE)
aicsum <- data.frame(matrix(ncol = 11, nrow = length(aic_lst)))
colnames(aicsum) <- c("Month", "BetaVal", "AICc", "Test AUC", "Training AUC", "Correlation", "Correlation P-Val", "TSS", "CBI", "No Omissions", "Prevalence")

for (a in 1:length(aic_lst)){
  aicr <- read.csv(aic_lst[a])
  mth <- str_sub(aic_lst[a], start = 25, end = 27) #selects the month from the filename
  aicsum$Month[a] <- mth
  aicres <- tail(aicr, 1)
  aicsum$BetaVal[a] <- aicres$beta
  aicsum$AICc[a] <- aicres$AICc
  aicsum$`Test AUC`[a] <- aicres$test_AUC
  aicsum$`Training AUC`[a] <- aicres$train_AUC
  aicsum$Correlation[a] <- aicres$test_evcor
  aicsum$`Correlation P-Val` <- aicres$test_evpcor
  aicsum$TSS[a] <- aicres$tss
  aicsum$CBI[a] <- aicres$cbi
  aicsum$`No Omissions`[a] <- aicres$test_no_omission
  aicsum$Prevalence[a] <- aicres$test_prevalence
}


mthord <- c("jan", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec") # a list of months to order by
aicsum <- aicsum[match(mthord, aicsum$Month), ] #reorder based on mthord
write.csv(aicsum, "../output/maxent/models/aicsummary.csv", row.names = FALSE)

```

stacked permutation importance plot on average

```{r permutation & jack data}
maxr_lst <- list.files("../output/maxent/models/", pattern = "maxentresults.csv", full.names = TRUE)
maxr_lst <- maxr_lst[-4] #removing january because this month has slightly different variables than the others
perm <- data.frame(matrix(ncol = 10, nrow = length(maxr_lst)))
colnames(perm) <- c("Month", "amo_sample", "amo_winter", "chl_surface", "nao_prev", "nao_sample", "nao_winter", "o2_depth", "salinity_depth", "temp_depth")
jack <- data.frame(matrix(ncol = 10, nrow = length(maxr_lst)))
colnames(jack) <- c("Month", "amo_sample", "amo_winter", "chl_surface", "nao_prev", "nao_sample", "nao_winter", "o2_depth", "salinity_depth", "temp_depth")

for (m in 1:length(maxr_lst)){
  maxr <- read.csv(maxr_lst[m])
  mth <- str_sub(maxr_lst[m], start = 25, end = 27) #selects the month from the filename
  perm$Month[m] <- mth
  jack$Month[m] <- mth
  maxt <- tail(maxr, 1)
  perm$amo_sample[m] <- maxt$amo_sample.permutation.importance
  perm$amo_winter[m] <- maxt$amo_winter.permutation.importance
  perm$chl_surface[m] <- maxt$chl_surface.permutation.importance
  perm$nao_prev[m] <- maxt$nao_prev.permutation.importance
  perm$nao_sample[m] <- maxt$nao_sample.permutation.importance
  perm$nao_winter[m] <- maxt$nao_winter.permutation.importance
  perm$o2_depth[m] <- maxt$o2_depth.permutation.importance
  perm$salinity_depth[m] <- maxt$salinity_depth.permutation.importance
  perm$temp_depth[m] <- maxt$temp_depth.permutation.importance

  jack$amo_sample[m] <- maxt$Training.gain.without.amo_sample
  jack$amo_winter[m] <- maxt$Training.gain.without.amo_winter
  jack$chl_surface[m] <- maxt$Training.gain.without.chl_surface
  jack$nao_prev[m] <- maxt$Training.gain.without.nao_prev
  jack$nao_sample[m] <- maxt$Training.gain.without.nao_sample
  jack$nao_winter[m] <- maxt$Training.gain.without.nao_winter
  jack$o2_depth[m] <- maxt$Training.gain.without.o2_depth
  jack$salinity_depth[m] <- maxt$Training.gain.without.salinity_depth
  jack$temp_depth[m] <- maxt$Training.gain.without.temp_depth
}


# now for january

maxr_lstj <- list.files("../output/maxent/models/", pattern = "janavgmaxentresults.csv", full.names = TRUE)
permj <- data.frame(matrix(ncol = 7, nrow = length(maxr_lstj)))
colnames(permj) <- c("Month", "chl_surface", "nao_sample", "nao_winter", "o2_depth", "salinity_depth", "temp_depth")
jackj <- data.frame(matrix(ncol = 7, nrow = length(maxr_lstj)))
colnames(jackj) <- c("Month", "chl_surface", "nao_sample", "nao_winter", "o2_depth", "salinity_depth", "temp_depth")

for (m in 1:length(maxr_lstj)){
  maxr <- read.csv(maxr_lstj[m])
  mth <- str_sub(maxr_lstj[m], start = 25, end = 27) #selects the month from the filename
  permj$Month[m] <- mth
  jackj$Month[m] <- mth
  maxt <- tail(maxr, 1)
  permj$chl_surface[m] <- maxt$chl_surface.permutation.importance
  permj$nao_sample[m] <- maxt$nao_sample.permutation.importance
  permj$nao_winter[m] <- maxt$nao_winter.permutation.importance
  permj$o2_depth[m] <- maxt$o2_depth.permutation.importance
  permj$salinity_depth[m] <- maxt$salinity_depth.permutation.importance
  permj$temp_depth[m] <- maxt$temp_depth.permutation.importance


  jackj$chl_surface[m] <- maxt$Training.gain.without.chl_surface
  jackj$nao_sample[m] <- maxt$Training.gain.without.nao_sample
  jackj$nao_winter[m] <- maxt$Training.gain.without.nao_winter
  jackj$o2_depth[m] <- maxt$Training.gain.without.o2_depth
  jackj$salinity_depth[m] <- maxt$Training.gain.without.salinity_depth
  jackj$temp_depth[m] <- maxt$Training.gain.without.temp_depth
}


permu <- rbind.fill(perm, permj)
jackk <- rbind.fill(jack, jackj)

mthord <- c("jan", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec") # a list of months to order by
permu <- permu[match(mthord, permu$Month), ] #reorder based on mthord
jackk <- jackk[match(mthord, jackk$Month), ] #reorder based on mthord

write.csv(permu, "../output/maxent/models/permutation_avg.csv", row.names = FALSE)
write.csv(jackk, "../output/maxent/models/jack_avg.csv", row.names = FALSE)

```

```{r}
maxr_lst <- list.files("../output/maxent/models/", pattern = "maxentresults.csv", full.names = TRUE)
maxr_lst <- maxr_lst[-4] #removing january because this month has slightly different variables than the others
jack_df <- list()
maxr_lstj <- list.files("../output/maxent/models/", pattern = "janavgmaxentresults.csv", full.names = TRUE)
jack_dfj <- list()


for (m in 1:length(maxr_lst)){
  res <- read.csv(maxr_lst[m], header = TRUE)
  mth <- str_sub(maxr_lst[m], start = 25, end = 27) #selects the month from the filename
  res_df <- tail(res, 1)
  var_df <- res_df[,c(grep("Training.gain.with*",names(res_df)))]
  var_df$id <- 1:nrow(var_df)
  var_df <- melt(var_df, id.vars=c("id"))
  jack_with <- var_df[grep("with.only",var_df$variable),]
  jack_with$Type_of_Run <- "With only the variable"
  jack_without <- var_df[grep("without",var_df$variable),]
  jack_without$Type_of_Run <- "Without the variable"
  gain_all <- res_df[c(grep("Regularized.",names(res_df)))]
  gain_all$id <- 1:nrow(gain_all)
  gain_all <- melt(gain_all, id.vars=c("id"))
  gain_all$Type_of_Run <- "With all variables"
  gain_all$variable <- "all_variables"
  jack_table <- rbind(jack_with,jack_without,gain_all)
  jack_table$state <- mth 
  

  jack_table$variable <- gsub(".*[.]","",jack_table$variable)
  jack_df[[m]] <- jack_table
}

var_jack <- do.call(rbind, jack_df)

for (m in 1:length(maxr_lstj)){
  res <- read.csv(maxr_lstj[m], header = TRUE)
  mth <- str_sub(maxr_lstj[m], start = 25, end = 27) #selects the month from the filename
  res_df <- tail(res, 1)
  var_df <- res_df[,c(grep("Training.gain.with*",names(res_df)))]
  var_df$id <- 1:nrow(var_df)
  var_df <- melt(var_df, id.vars=c("id"))
  jack_with <- var_df[grep("with.only",var_df$variable),]
  jack_with$Type_of_Run <- "With only the variable"
  jack_without <- var_df[grep("without",var_df$variable),]
  jack_without$Type_of_Run <- "Without the variable"
  gain_all <- res_df[c(grep("Regularized.",names(res_df)))]
  gain_all$id <- 1:nrow(gain_all)
  gain_all <- melt(gain_all, id.vars=c("id"))
  gain_all$Type_of_Run <- "With all variables"
  gain_all$variable <- "all_variables"
  jack_table <- rbind(jack_with,jack_without,gain_all)
  jack_table$state <- mth 
  

  jack_table$variable <- gsub(".*[.]","",jack_table$variable)
  jack_dfj[[m]] <- jack_table
}

var_jackj <- do.call(rbind, jack_dfj)

var_jack$state <- factor(var_jack$state,levels=c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"))
var_jack$Type_of_Run <- factor(var_jack$Type_of_Run,levels=c("With all variables", "Without the variable","With only the variable"))
var_jackj$state <- factor(var_jackj$state,levels="jan")
var_jackj$Type_of_Run <- factor(var_jackj$Type_of_Run,levels=c("With all variables", "Without the variable","With only the variable"))
a <- subset(var_jack, state == "mar" | state == "apr" |state == "may" | state == "jun" | state == "jul")
b <- subset(var_jack, state == "aug" | state == "sep" |state == "oct" | state == "nov" | state == "dec")
c <- subset(var_jackj, state == "jan")

plotlst <- list(a, b, c)

color_type_1 <- c("#000000", "#009E73","#999999")

for (p in 1:length(plotlst)){
  pt <- p
  dev.new()
  jack <- ggplot(plotlst[[p]], aes(variable,value))+
  geom_bar(aes(fill=Type_of_Run),position="dodge",stat="identity")+ coord_flip()+ facet_grid(state~., scales="free", space = "free")+
  theme_bw(14)+
  scale_fill_manual(values=color_type_1,guide=guide_legend(reverse=TRUE))+
  theme(axis.text=element_text(size=8)) +
  theme(legend.title=element_blank())+
  theme(legend.position="top")+
  theme(strip.text=element_text(size=12))+
  theme(strip.text.y = element_text(angle = 0)) +
  labs(x="Variable",y="Jackknife of Regularized Training Gain")
  ggsave(filename = paste0("../output/maxent/models/jackknife_plot_", pt, ".png"), plot = jack, dpi = 900, height = 9, width = 7)
  dev.off()
}


#png("../output/maxent/models/jackknife_plot.png")
#print(jack)
#dev.off()
```





```{r permulation plot}
permelt <- melt(permu, id = "Month") #need to melt the data into this format for ggplot
perpl <- ggplot(data = permelt, aes(x = Month, y = value, fill = variable)) + geom_bar(stat = "identity") + scale_fill_brewer(palette = "Set1")
png("../output/maxent/models/permutation_plot.png")
print(perpl)
dev.off()

#for jan

permuj <- subset(permu, Month == "jan")
permelt <- melt(permuj, id = "Month") #need to melt the data into this format for ggplot
perpl <- ggplot(data = permelt, aes(x = Month, y = value, fill = variable)) + geom_bar(stat = "identity") + scale_fill_brewer(palette = "Set1")
png("../output/maxent/models/permutation_plot_jan.png")
print(perpl)
dev.off()
```

```{r jackknife plot}
color_type_1 <- c("#000000", "#009E73","#999999")
jackpl <- ggplot(jackk, aes(x = variable, y = value)) + geom_bar(aes(fill=Type_of_Run),position="dodge",stat="identity")+
```


#binary maps - individual year layers

there seem to be two primary ways to create binary maps. the most common for conservation purposes seems to be to use maxsumspensspec values, however MPA also comes recommended (but is def less common). 

the thresholds are in the monthavgAIC.csv file in the model folder (not model/month)

```{r set up threshold binary function}
binmpa <- function(x) {
  ifelse(x <  mpa_thr, 0,
  ifelse(x >=  mpa_thr, 1, NA))
  }
```


```{r binary maps on individual layers cloglog}
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)

for (modtime in 1:nrow(modelmonth)){
  timeslice <- modelmonth[modtime]
  print(timeslice)
  yr <- str_sub(timeslice, -4)
  thresholds <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
  mpa_thr <- thresholds$mpa_0.9_clog
  for (cum in 1:length(clogasc_list)){
    cumascyr <- str_sub(clogasc_list[cum], start = 44, end = 47) #selects the year from the file name
    if(yr == cumascyr){
      cumasc <- raster(clogasc_list[cum])
      ascname <- names(cumasc)
      cum_mpathr <- calc(cumasc, fun = binmpa)
      writeRaster(cum_mpathr, paste0("../output/maxent/predictions/", mthna,  "/binary_", ascname, ".asc"), overwrite = TRUE)
      plot(cum_mpathr, png(paste0("../output/maxent/predictions/", mthna, "/binary_", ascname, ".png")), overwrite = TRUE)
      dev.off() # stops automatic saving of the plot to a png
    }
  }
}
```

now for each year create a 2-d representation of suitable habitat

need to stack the rasters by year
run cellStats (sum)
save the output as they year

```{r binary map per year 2D representation}
binaryclog_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_cloglog.*.asc", full.names = TRUE)
yrlayer <- data.frame(matrix(ncol = 2, nrow = length(binaryclog_list)))
colnames(yrlayer) <- c("layer", "year")

for (yrlyr in 1:length(binaryclog_list)){
  yearoflyr <- str_sub(binaryclog_list[yrlyr], start = 51, end = 54) #selects the year from the file name
  yrlayer$year[yrlyr] <- yearoflyr
  yrlayer$layer[yrlyr] <- binaryclog_list[yrlyr]
}

y_list <- split(yrlayer, yrlayer$year)
noyrs <- unique(yrlayer$year)

for (binyr in (1:length(y_list))){
  binstack <- stack(y_list[[binyr]]$layer)
  year <- y_list[[binyr]]$year[1]
  stacksum <- sum(binstack, na.rm = TRUE)
  writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_2d_", year, ".asc"), overwrite=TRUE)
  plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_2d_", year, ".png")))
  dev.off()
}
  
```




#using averageing

ok! now to average results:

- the AICforMaxentReg.csv 
- the maxentResults.csv
- the asc files per depth layer

open all maxentReg files



for this bit may need to stack rasters by depth... this will need some working with the name
get unique filenames into a list
ignore the first X characters in the filename (yr_mthna_) and stack based on the last bit of the filename
then do something probably with raster package

```{r avg asc layers cloglog}
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)
stdep <- read.csv(paste0("../output/maxent/models/", timeslice, "/stack_depth.csv"), header = TRUE)
depthlayers <- data.frame(cbind(unique(stdep$ascdepths)))
names(depthlayers)[names(depthlayers) == "cbind.unique.stdep.ascdepths.."] <- "depth"
depthlayers$depth <- as.character(depthlayers$depth)

colno <- 1

for (d in 1:nrow(depthlayers)){
  dep <- depthlayers$depth[d]
  for (a in 1:length(clogasc_list)){
    asc <- clogasc_list[a]
    if (grepl(dep, asc)){
      depthlayers[d , paste0("a", colno)] <- asc
        colno <- colno+1
    }
  }
}
write.csv(depthlayers, (paste0("../output/maxent/predictions/", mthna, "/cloglog_asclayerbydepth.csv")), row.names = TRUE)



for (x in 1:nrow(depthlayers)){
  asclay <- depthlayers[x, ]
  asclay <- asclay[!is.na(asclay)]
  asclay <- as.data.frame(rbind(asclay))
  asclay$V1 <- as.character(asclay$V1) #v1 corresponds to depth
  asclay$V2 <- as.character(asclay$V2) #v2 to end corresponds to year
  asclay$V3 <- as.character(asclay$V3)
  asclay$V4 <- as.character(asclay$V4)
  asclay$V5 <- as.character(asclay$V5)
  asclay$V6 <- as.character(asclay$V6)
  asclay$V7 <- as.character(asclay$V7)
  asclay$V8 <- as.character(asclay$V8)
  asclay$V9 <- as.character(asclay$V9)
  asclay$V10 <- as.character(asclay$V10)
  asclay$V11 <- as.character(asclay$V11)
  asclay$V12 <- as.character(asclay$V12)
  asclay$V13 <- as.character(asclay$V13)
  asclay$V14 <- as.character(asclay$V14)
  asclay$V15 <- as.character(asclay$V15)  


  
  asclaydep <- asclay$V1
  
  asc1998 <- raster(asclay$V2)
  asc1999 <- raster(asclay$V3)
  asc2000 <- raster(asclay$V4)
  asc2001 <- raster(asclay$V5)
  asc2002 <- raster(asclay$V6)
  asc2003 <- raster(asclay$V7)
  asc2004 <- raster(asclay$V8)
  asc2005 <- raster(asclay$V9)
  asc2006 <- raster(asclay$V10)
  asc2007 <- raster(asclay$V11)
  asc2008 <- raster(asclay$V12)
  asc2009 <- raster(asclay$V13)
  asc2010 <- raster(asclay$V14)
  asc2011 <- raster(asclay$V15)


  stkasc <- stack(asc1998, asc1999, asc2000, asc2001, asc2002, asc2003, asc2004, asc2005, asc2006, asc2007, asc2008, asc2009, asc2010, asc2011)

  avg <- mean(stkasc, na.rm = TRUE)
  
  writeRaster(avg, paste0("../output/maxent/predictions/", mthna, "/avg_cloglog_", asclaydep, ".asc"), overwrite=TRUE)
  avgplot <- plot(avg, png(paste0("../output/maxent/predictions/", mthna, "/avg_cloglog_", asclaydep, ".png"))) 
  dev.off()
}
```




```{r binary maps on averaged depth layer}
avgasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^avg_cloglog_.*.asc", full.names = TRUE)
thresholds <- read.csv(paste0("../output/maxent/models/", mthna, "avgAIC.csv"), header = TRUE)
thresholds <- tail(thresholds, 1) #subset the last row
mpa_thr <- thresholds$mpa_0.9_clog

for (avg in 1:length(avgasc_list)){
    cumasc <- raster(avgasc_list[avg])
    ascname <- names(cumasc)
    mpathr <- calc(cumasc, fun = binmpa)
    mpa_plot <- plot(mpathr, png(paste0("../output/maxent/predictions/", mthna, "/binary_", ascname, ".png")))
    dev.off() # stops automatic saving of the plot to a png
    writeRaster(mpathr, paste0("../output/maxent/predictions/", mthna, "/binary_", ascname, ".asc"), overwrite = TRUE)
}

```

```{r binary map averaged 2D representation}
binaryclog_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_cloglog.*.asc", full.names = TRUE)

binstack <- stack(binaryclog_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_avg_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_avg_2d.png")))
dev.off()

```


#plots by depth for MPA threshold

first need some statistcs... for each layer how many cells have a value of 1...

```{r calc no presence cells per layer (avg)} 
ascdepth_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_cloglog.*asc", full.names = TRUE)
binaryavgstack <- stack(ascdepth_list)
stackstat <- data.frame(matrix(ncol = 2, nrow = nlayers(binaryavgstack)))
stackstat[ ,1] <- c(1:49)
colnames(stackstat) <- c("layer", "cell_sum")

for (lyr in 1:nlayers(binaryavgstack)){
  lyrsum <- cellStats(binaryavgstack[[lyr]], sum)
  stackstat$cell_sum[lyr] <- lyrsum
}

write.csv(stackstat, paste0("../output/maxent/predictions/", mthna, "/cellcount_bydepth_avg.csv"), row.names = FALSE)
```


a crude plot but ok to show slr

```{r graph by depth (avg)}
bydepth <- barchart(layer ~ cell_sum, data = stackstat, ylim = c(49, 1))
trellis.device(device="png", filename = paste0("../output/maxent/predictions/", mthna, "/depthplot_avg.png"))
print(bydepth)
dev.off()
```

#probability selected maps

```{r habitat classification on probability - 3 classifications}

binprob <- function(x){
  ifelse(x >= 0.8, 3,
  ifelse(x >= 0.7 & x <0.8, 2,
  ifelse(x >= 0.6 & x <0.7, 1,
  ifelse(x < 0.6, 0, NA)))) 
}


  modelmonth <- cbind(paste0(mthna, unique(prback$year)))
  clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)

  for (modtime in 1:nrow(modelmonth)){
    timeslice <- modelmonth[modtime]
    yr <- str_sub(timeslice, -4)
    for (cum in 1:length(clogasc_list)){
      cumascyr <- str_sub(clogasc_list[cum], start = 44, end = 47) #selects the year from the file name
      if(yr == cumascyr){
        cumasc <- raster(clogasc_list[cum])
        ascname <- names(cumasc)
        probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
        writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_prob_", ascname, ".asc"), overwrite = TRUE)
        plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_prob_", ascname, ".png")), overwrite = TRUE)
        dev.off() # stops automatic saving of the plot to a png
      }
    }
  }
```

```{r habitat classification on probability - high only}

binprob <- function(x){
  ifelse(x >= 0.8, 1,
  ifelse(x < 0.8, 0, NA)) 
}


modelmonth <- cbind(paste0(mthna, unique(prback$year)))
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)

  for (modtime in 1:nrow(modelmonth)){
    timeslice <- modelmonth[modtime]
    yr <- str_sub(timeslice, -4)
    for (cum in 1:length(clogasc_list)){
      cumascyr <- str_sub(clogasc_list[cum], start = 44, end = 47) #selects the year from the file name
      if(yr == cumascyr){
        cumasc <- raster(clogasc_list[cum])
        ascname <- names(cumasc)
        probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
        writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_highprob_", ascname, ".asc"), overwrite = TRUE)
        plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_highprob_", ascname, ".png")), overwrite = TRUE)
        dev.off() # stops automatic saving of the plot to a png
      }
    }
  }

```


```{r habitat classification on probability - med only}
binprob <- function(x){
  ifelse(x >= 0.7 & x <0.8, 1,
  ifelse(x < 0.7, 0, NA)) 
}


modelmonth <- cbind(paste0(mthna, unique(prback$year)))
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)

  for (modtime in 1:nrow(modelmonth)){
    timeslice <- modelmonth[modtime]
    yr <- str_sub(timeslice, -4)
    for (cum in 1:length(clogasc_list)){
      cumascyr <- str_sub(clogasc_list[cum], start = 44, end = 47) #selects the year from the file name
      if(yr == cumascyr){
        cumasc <- raster(clogasc_list[cum])
        ascname <- names(cumasc)
        probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
        writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_medprob_", ascname, ".asc"), overwrite = TRUE)
        plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_medprob_", ascname, ".png")), overwrite = TRUE)
        dev.off() # stops automatic saving of the plot to a png
      }
    }
  }
```

```{r habitat classification on probability - low only}
binprob <- function(x){
  ifelse(x >= 0.6 & x <0.7, 1,
  ifelse(x < 0.6, 0, NA)) 
}


modelmonth <- cbind(paste0(mthna, unique(prback$year)))
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)

  for (modtime in 1:nrow(modelmonth)){
    timeslice <- modelmonth[modtime]
    yr <- str_sub(timeslice, -4)
    for (cum in 1:length(clogasc_list)){
      cumascyr <- str_sub(clogasc_list[cum], start = 44, end = 47) #selects the year from the file name
      if(yr == cumascyr){
        cumasc <- raster(clogasc_list[cum])
        ascname <- names(cumasc)
        probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
        writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_lowprob_", ascname, ".asc"), overwrite = TRUE)
        plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_lowprob_", ascname, ".png")), overwrite = TRUE)
        dev.off() # stops automatic saving of the plot to a png
      }
    }
  }
```

now you need to do summary maps....


```{r high probability map per year 2D representation}
binaryprob_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_highprob_cloglog.*.asc", full.names = TRUE)
yrlayer <- data.frame(matrix(ncol = 2, nrow = length(binaryprob_list)))
colnames(yrlayer) <- c("layer", "year")

for (yrlyr in 1:length(binaryprob_list)){
  yearoflyr <- str_sub(binaryprob_list[yrlyr], start = 60, end = 63) #selects the year from the file name
  yrlayer$year[yrlyr] <- yearoflyr
  yrlayer$layer[yrlyr] <- binaryprob_list[yrlyr]
}

y_list <- split(yrlayer, yrlayer$year)
noyrs <- unique(yrlayer$year)

for (binyr in (1:length(y_list))){
  binstack <- stack(y_list[[binyr]]$layer)
  year <- y_list[[binyr]]$year[1]
  stacksum <- sum(binstack, na.rm = TRUE)
  writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/highprob_2d_", year, ".asc"), overwrite=TRUE)
  plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/highprob_2d_", year, ".png")))
  dev.off()
}
  
```

```{r med probability map per year 2D representation}
binaryprob_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_medprob_cloglog.*.asc", full.names = TRUE)
yrlayer <- data.frame(matrix(ncol = 2, nrow = length(binaryprob_list)))
colnames(yrlayer) <- c("layer", "year")

for (yrlyr in 1:length(binaryprob_list)){
  yearoflyr <- str_sub(binaryprob_list[yrlyr], start = 59, end = 62) #selects the year from the file name
  yrlayer$year[yrlyr] <- yearoflyr
  yrlayer$layer[yrlyr] <- binaryprob_list[yrlyr]
}

y_list <- split(yrlayer, yrlayer$year)
noyrs <- unique(yrlayer$year)

for (binyr in (1:length(y_list))){
  binstack <- stack(y_list[[binyr]]$layer)
  year <- y_list[[binyr]]$year[1]
  stacksum <- sum(binstack, na.rm = TRUE)
  writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/medprob_2d_", year, ".asc"), overwrite=TRUE)
  plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/medprob_2d_", year, ".png")))
  dev.off()
}
  
```

```{r low probability map per year 2D representation}
binaryprob_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_lowprob_cloglog.*.asc", full.names = TRUE)
yrlayer <- data.frame(matrix(ncol = 2, nrow = length(binaryprob_list)))
colnames(yrlayer) <- c("layer", "year")

for (yrlyr in 1:length(binaryprob_list)){
  yearoflyr <- str_sub(binaryprob_list[yrlyr], start = 59, end = 62) #selects the year from the file name
  yrlayer$year[yrlyr] <- yearoflyr
  yrlayer$layer[yrlyr] <- binaryprob_list[yrlyr]
}

y_list <- split(yrlayer, yrlayer$year)
noyrs <- unique(yrlayer$year)

for (binyr in (1:length(y_list))){
  binstack <- stack(y_list[[binyr]]$layer)
  year <- y_list[[binyr]]$year[1]
  stacksum <- sum(binstack, na.rm = TRUE)
  writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/lowprob_2d_", year, ".asc"), overwrite=TRUE)
  plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/lowprob_2d_", year, ".png")))
  dev.off()
}
  
```

now average probability split maps - again low, med, high and all

```{r habitat classification on average probability - 3 classifications}

binprob <- function(x){
  ifelse(x >= 0.8, 3,
  ifelse(x >= 0.7 & x <0.8, 2,
  ifelse(x >= 0.6 & x <0.7, 1,
  ifelse(x < 0.6, 0, NA)))) 
}


clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^avg_cloglog_.*.asc", full.names = TRUE)

    for (cum in 1:length(clogasc_list)){
      cumasc <- raster(clogasc_list[cum])
      ascname <- names(cumasc)
      probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
      writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_avgprob_", ascname, ".asc"), overwrite = TRUE)
      plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_avgprob_", ascname, ".png")), overwrite = TRUE)
      dev.off() # stops automatic saving of the plot to a png
    }
  
```

```{r habitat classification on average probability - high}

binprob <- function(x){
  ifelse(x >= 0.8, 1,
  ifelse(x < 0.8, 0, NA))  
}


clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^avg_cloglog_.*.asc", full.names = TRUE)

    for (cum in 1:length(clogasc_list)){
      cumasc <- raster(clogasc_list[cum])
      ascname <- names(cumasc)
      probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
      writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_avg_highprob_", ascname, ".asc"), overwrite = TRUE)
      plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_avg_highprob_", ascname, ".png")), overwrite = TRUE)
      dev.off() # stops automatic saving of the plot to a png
    }
  
```

```{r habitat classification on average probability - med}

binprob <- function(x){
  ifelse(x >= 0.7 & x <0.8, 1,
  ifelse(x < 0.7, 0, NA)) 
}


clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^avg_cloglog_.*.asc", full.names = TRUE)

    for (cum in 1:length(clogasc_list)){
      cumasc <- raster(clogasc_list[cum])
      ascname <- names(cumasc)
      probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
      writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_avg_medprob_", ascname, ".asc"), overwrite = TRUE)
      plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_avg_medprob_", ascname, ".png")), overwrite = TRUE)
      dev.off() # stops automatic saving of the plot to a png
    }
  
```

```{r habitat classification on average probability - low}

binprob <- function(x){
  ifelse(x >= 0.6 & x <0.7, 1,
  ifelse(x < 0.6, 0, NA)) 
}


clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^avg_cloglog_.*.asc", full.names = TRUE)

    for (cum in 1:length(clogasc_list)){
      cumasc <- raster(clogasc_list[cum])
      ascname <- names(cumasc)
      probbin <- calc(cumasc, fun = binprob) #creates raster layer with cell values based on the binprob function
      writeRaster(probbin, paste0("../output/maxent/predictions/", mthna,  "/binary_avg_lowprob_", ascname, ".asc"), overwrite = TRUE)
      plot(probbin, png(paste0("../output/maxent/predictions/", mthna, "/binary_avg_lowprob_", ascname, ".png")), overwrite = TRUE)
      dev.off() # stops automatic saving of the plot to a png
    }
  
```

```{r high probability average map per year 2D representation}
binaryprob_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_highprob.*.asc", full.names = TRUE)

binstack <- stack(binaryprob_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_highavg_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_highprob_avg_2d.png")))
dev.off()
```
```{r med probability average map per year 2D representation}
binaryprob_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_medprob.*.asc", full.names = TRUE)

binstack <- stack(binaryprob_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_medavg_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_medprob_avg_2d.png")))
dev.off()
```

```{r low probability average map per year 2D representation}
binaryprob_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_lowprob.*.asc", full.names = TRUE)

binstack <- stack(binaryprob_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_lowavg_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_lowprob_avg_2d.png")))
dev.off()
```


first need some statistcs... for each layer how many cells have a value of 1...

```{r calc no presence cells per layer (avg probability)} 
ascdepth_list_high <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_highprob_.*asc", full.names = TRUE)
ascdepth_list_med <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_medprob_.*asc", full.names = TRUE)
ascdepth_list_low <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_lowprob_.*asc", full.names = TRUE)


binaryavgstack <- stack(ascdepth_list_high)
stackstathigh <- data.frame(matrix(ncol = 2, nrow = nlayers(binaryavgstack)))
stackstathigh[ ,1] <- c(1:49)
colnames(stackstathigh) <- c("layer", "high_cell_sum")

for (lyr in 1:nlayers(binaryavgstack)){
  lyrsum <- cellStats(binaryavgstack[[lyr]], sum)
  stackstathigh$high_cell_sum[lyr] <- lyrsum
}

binaryavgstack <- stack(ascdepth_list_med)
stackstatmed <- data.frame(matrix(ncol = 2, nrow = nlayers(binaryavgstack)))
stackstatmed[ ,1] <- c(1:49)
colnames(stackstatmed) <- c("layer", "med_cell_sum")

for (lyr in 1:nlayers(binaryavgstack)){
  lyrsum <- cellStats(binaryavgstack[[lyr]], sum)
  stackstatmed$med_cell_sum[lyr] <- lyrsum
}

binaryavgstack <- stack(ascdepth_list_low)
stackstatlow <- data.frame(matrix(ncol = 2, nrow = nlayers(binaryavgstack)))
stackstatlow[ ,1] <- c(1:49)
colnames(stackstatlow) <- c("layer", "low_cell_sum")

for (lyr in 1:nlayers(binaryavgstack)){
  lyrsum <- cellStats(binaryavgstack[[lyr]], sum)
  stackstatlow$low_cell_sum[lyr] <- lyrsum
}

stackstat <- cbind(stackstathigh, stackstatmed[ , 2], stackstatlow[ ,2])
colnames(stackstat) <- c("layer", "high", "med", "low")
stackstat <- melt(stackstat, id = "layer")

write.csv(stackstat, paste0("../output/maxent/predictions/", mthna, "/probability_cellcount_bydepth_avg.csv"), row.names = FALSE)
```


a crude plot but ok to show slr

```{r graph by depth - prob plot (avg)}
bydepth <- ggplot(data = stackstat, aes(x = layer, y = value, fill = variable)) + geom_bar(stat = "identity") +   scale_x_reverse() +
coord_flip()
png(paste0("../output/maxent/predictions/", mthna, "/depthplot_probavg.png"))
print(bydepth)
dev.off()
```


#which cells are used in all months?

start with mpa binary map first - based on averages

```{r get all csvs in one database}
mthlst <- c("jan", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")
stdep <- read.csv("../output/maxent/models/dec1998/stack_depth.csv", header = TRUE)
depthlayers <- data.frame(cbind(unique(stdep$ascdepths)))
names(depthlayers)[names(depthlayers) == "cbind.unique.stdep.ascdepths.."] <- "depth"
depthlayers$depth <- as.character(depthlayers$depth)


for(m in 1:length(mthlst)){
  mthna <- mthlst[m]
#mthna <- "jan"
  mpabin_lst <- list.files(paste0("../output/maxent/predictions/", mthna), pattern =  "^binary_avg_cloglog.*.asc", full.names = TRUE)


  
  for (d in 1:nrow(depthlayers)){
    dep <- depthlayers$depth[d]
    for (a in 1:length(mpabin_lst)){
      asc <- mpabin_lst[a]
      if (grepl(dep, asc)){
        depthlayers[d , paste0(mthna)] <- asc
        
      }
    }
  }
  write.csv(depthlayers, ("../output/maxent/predictions/all_cells/binary_avg_asclayerbydepth.csv"), row.names = FALSE)
}

```

```{r create stacks by depth}
depthlayers <- read.csv("../output/maxent/predictions/all_cells/binary_avg_asclayerbydepth.csv", header = TRUE)


for (x in 1:nrow(depthlayers)){
  asclay <- depthlayers[x, ]
  asclay <- asclay[!is.na(asclay)]
  asclay <- as.data.frame(rbind(asclay))
  asclay$V1 <- as.character(asclay$V1) #v1 corresponds to depth
  asclay$V2 <- as.character(asclay$V2) #v2 to end corresponds to month
  asclay$V3 <- as.character(asclay$V3)
  asclay$V4 <- as.character(asclay$V4)
  asclay$V5 <- as.character(asclay$V5)
  asclay$V6 <- as.character(asclay$V6)
  asclay$V7 <- as.character(asclay$V7)
  asclay$V8 <- as.character(asclay$V8)
  asclay$V9 <- as.character(asclay$V9)
  asclay$V10 <- as.character(asclay$V10)
  asclay$V11 <- as.character(asclay$V11)
  asclay$V12 <- as.character(asclay$V12)


  
  asclaydep <- asclay$V1
  
  ascjan <- raster(asclay$V2)
  ascmar <- raster(asclay$V3)
  ascapr <- raster(asclay$V4)
  ascmay <- raster(asclay$V5)
  ascjun <- raster(asclay$V6)
  ascjul <- raster(asclay$V7)
  ascaug <- raster(asclay$V8)
  ascsep <- raster(asclay$V9)
  ascoct <- raster(asclay$V10)
  ascnov <- raster(asclay$V11)
  ascdec <- raster(asclay$V12)



  stkasc <- stack(ascjan, ascmar, ascapr, ascmay, ascjun, ascjul, ascaug, ascsep, ascoct, ascnov, ascdec)

  avg <- sum(stkasc, na.rm = TRUE)
  
  writeRaster(avg, paste0("../output/maxent/predictions/all_cells/count_cells_used_all_months_mpa", asclaydep, ".asc"), overwrite=TRUE)
  avgplot <- plot(avg, png(paste0("../output/maxent/predictions/all_cells/count_cells_used_all_months_mpa", asclaydep, ".png")), overwrite = TRUE) 
  dev.off()
}

```

```{r create rasters showing cells that are suitable in all 11 months}
cellslst <- list.files("../output/maxent/predictions/all_cells", pattern =  "^count_cells_used_all_months_mpa.*.asc", full.names = TRUE)

allcell <- function(x){
  ifelse(x == 12, 1,
  ifelse(x < 12, 0, NA)) 
}

for (r in 1:length(cellslst)){
  ras <- raster(cellslst[r])
  ascname <- names(ras)
  allc <- calc(ras, fun = allcell)
  writeRaster(allc, paste0("../output/maxent/predictions/all_cells/total_cells_used_all_months_mpa", ascname, ".asc"), overwrite = TRUE)
  plot(allc, png(paste0("../output/maxent/predictions/all_cells/total_cells_used_all_months_mpa", ascname, ".png")), overwrite = TRUE)
  dev.off() # stops automatic saving of the plot to a png
  
}
```

there are no cells that are used in every month....



# quickly adding some black to some plots for mj slr
```{r}
mthlst <- c("jan", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

for(m in 1:length(mthlst)){
  mthna <- mthlst[m]
  replst11 <- list.files(paste0("../output/maxent/predictions/", mthna), pattern =  ".*11.7737.*.asc", full.names = TRUE)
  replst221 <- list.files(paste0("../output/maxent/predictions/", mthna), pattern =  ".*221.141.*.asc", full.names = TRUE)
  replst508 <- list.files(paste0("../output/maxent/predictions/", mthna), pattern =  ".*508.64.*.asc", full.names = TRUE)
  replst <- c(replst11, replst221, replst508)
  for (r in 1:length(replst)){
    ras <- raster(replst[r])
    ascname <- names(ras)
    plot(ras, colNA = 'black', png(paste0("../output/maxent/predictions/", mthna, "/", ascname, ".png")), overwrite = TRUE)
    dev.off()
  }
}


replst163 <- list.files("../output/maxent/predictions/jul/", pattern =  ".*163..*.asc", full.names = TRUE)
for (r in 1:length(replst163)){
    ras <- raster(replst163[r])
    ascname <- names(ras)
    plot(ras, colNA = 'black', png(paste0("../output/maxent/predictions/jul/", ascname, ".png")), overwrite = TRUE)
    dev.off()
}

back <- raster("../output/maxent/predictions/mar/binary_avg_medprob_avg_cloglog_1.55586.asc")
replst163 <- list.files("../output/maxent/predictions/jan/", pattern =  ".*avg_2d.*.asc", full.names = TRUE)
for (r in 1:length(replst163)){
    ras <- raster(replst163[r])
    ascname <- names(ras)
    bkras <- overlay(back, ras, fun=function(x,y){return(x+y)})
    plot(bkras, colNA = 'black', png(paste0("../output/maxent/predictions/jan/", ascname, ".png")), overwrite = TRUE)
    dev.off()
}




```
