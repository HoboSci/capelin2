---
title: "maxent model avec xvalidation"
author: "Samantha Andrews"
output: html_notebook
---

# Overview
A note to anyone who might happen to stumble across this... I am a beginner in R and have had no exposure to similar languages. I don't know what I'm doing. The code herein is unlikely to be elegant and there area probably more efficient ways of running the code.

Built with 'r getRversion()'..

# Package dependencies
You can install and load them using the following code which uses a function called [ipak](https://gist.github.com/stevenworthington/3178163). Note this function checks to see if the packages are installed first before loading.


```{r pre-install & load packages, include=FALSE}
packages <- c("dismo", "stringr")
source("../src/ipak.R")
ipak(packages)
```


#load the presence-background dataset 
("../output/bio/presab_nafo_yr.csv")

```{r load pres-background dataset}
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)
colnames(presback)
```

this dataset contains a lot of columns you don't need for the maxent models. Remove them here

```{r remove unnecessary columns}
presback <- subset(presback, select = -c(cell_id, id, decimalLatitude, decimalLongitude, datecollected, institutioncode, individualcount, depth, resname, originalscientificname, collectioncode, day, nafo_zone, gear, longitude_meters, latitude_meters, total_cell_obs_xy, total_cell_obs_xyt, bottom_depth, XXtotal_cell_obs_xyzt, temp_celsius_depth, temp_celsius_surface, longitude_meters.1, latitude_meters.1, bottom_depth_glorys, longitude_meters.2, latitude_meters.2, cell_id_3d, total_cell_obs_xyzt, cell_id_xyzt))
colnames(presback)
```

#monthly model data selection and prep
For each monthly model, subset the data to the month you want, and the variables you want (Based on spearmans and VIF)

jan variables to keep: temp_depth, salinty_depth, o2_depth, chl_surface, nao_sample, nao_winter 
```{r january data}
janprback <- subset(presback, month == "1")
janprback <- subset(janprback, select = c(occurrence, year, temp_depth, salinity_depth, o2_depth, chl_surface, nao_sample, nao_winter))
```

now each month contains NAs - lets remove these (maxent principle doesnt allow for missing data - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.5607&rep=rep1&type=pdf)

```{r jan remove na vals}
janprback <- janprback[!is.na(janprback$temp_depth), ]
janprback <- janprback[!is.na(janprback$salinity_depth), ]
janprback <- janprback[!is.na(janprback$o2_depth), ]
janprback <- janprback[!is.na(janprback$chl_surface), ]
janprback <- janprback[!is.na(janprback$nao_sample), ]
janprback <- janprback[!is.na(janprback$nao_winter), ]
```


normal model..
mod12 <- maxent(x = prab, p = pa, file = .asc, args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE")) 
mod12

```{r train and test on jan inc AIC for reg val}
mth <- "jan"
modelmonth <- cbind(paste0(mth ,unique(janprback$year)))
aicetc <- read.csv("../data/env/AICcCalculations.csv", header = TRUE) #pre-created csv file
betavallist <- cbind(aicetc$regularization)

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(janprback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(janprback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  
  for (h in 1:nrow(betavallist)){
    betamval <-  betavallist[h]
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/", timeslice), args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betavallist[h])))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2])) #dodgy 
    bic <- (bick*log(sum(trainpa == 1)) - 2*11) #dodgy
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    
  
    for (i in 1:nrow(aicetc)){
      if(aicetc$regularization[i] == betamval){
      aicetc$Train.AUC[i] <- trainauc
      aicetc$n[i] <- notrainingpoints
      aicetc$coefficients[i] <- nocoeff
      aicetc$sum.of.logs[i] <- sumsamplepred
      aicetc$Test.AUC[i] <- evauc
      aicetc$evcor[i] <- evcor
      aicetc$evpcor[i] <- evpcor
      aicetc$nopresence[i] <- evnp
      aicetc$nobackground[i] <- evna
      aicetc$maxsumsenspec[i] <- evmaxtprtnr
      aicetc$maxsumsenspec[i] <- evmaxkap
      aicetc$no_omission[i] <- evno_omission
      aicetc$equal_sens_spec[i] <- evequal_sens_spec
      aicetc$bic[i] <- bic #not sure this is correct...
      }
    }
  }

aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$n/(aicetc$n - aicetc$coefficients-1))))

write.csv(aicetc, paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)

}

```

#model selection
next step... select the models you want for each year and run those models again (primarily based on lowest AICc but check test AUC and other things too)

jan2003: b = 1
jan2004: b = 1
jan2005: b = 1.5
jan2006: b = 2.25


```{r final models plus predict}
mth <- "jan"
modelmonth <- cbind(paste0(mth, unique(janprback$year)))
aicetc <- read.csv("../data/env/AICcFinalmod.csv", header = TRUE) #pre-created csv file
unlayer <- read.csv(paste0("../data/env/asc_layerlist", mth, ".csv"), header = TRUE) #if code doesnt work put back to unlayer_yr

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(janprback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(janprback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling

  
  if (timeslice == "jan2003"){
    betaval <- 1
  } else if (timeslice == "jan2004"){
    betaval <- 1
  } else if (timeslice == "jan2005"){
    betaval <- 1.5
  } else if (timeslice == "jan2006"){
    betaval <- 2.25
  }
  
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/", timeslice), args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betaval)))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2]))
    bic <- (bick*log(sum(trainpa == 1)) - 2*11)
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    
  
      aicetc$Train.AUC <- trainauc
      aicetc$n <- notrainingpoints
      aicetc$coefficients <- nocoeff
      aicetc$sum.of.logs <- sumsamplepred
      aicetc$Test.AUC <- evauc
      aicetc$evcor <- evcor
      aicetc$evpcor <- evpcor
      aicetc$nopresence <- evnp
      aicetc$nobackground <- evna
      aicetc$maxsumsenspec <- evmaxtprtnr
      aicetc$maxsumsenspec <- evmaxkap
      aicetc$no_omission <- evno_omission
      aicetc$equal_sens_spec <- evequal_sens_spec
      aicetc$bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$n/(aicetc$n - aicetc$coefficients-1))))

    write.csv(aicetc, paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)


    unlayer_yr <- subset(unlayer, ascyears == yr)
    unlayer_yr <- unlayer_yr[-c(1), ]
    unlayer_yr[] <- lapply(unlayer_yr, as.character) #from https://stackoverflow.com/questions/2851015/convert-data-frame-columns-from-factors-to-characters
    stackdep <- subset(unlayer_yr, select = c(stackname, ascdepths))
    stackdeplst[[year]] <- stackdep
    #write.csv(stackdep, paste0("../output/maxent/predictions/stackdepthlist_", yr, ".csv"), row.names = FALSE)
    aea <- raster("../output/env/aea.tif") 

    for (td in 1:nrow(unlayer_yr)){
      temp_depth <- raster(unlayer_yr$temp_depth[td])
      crs(temp_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(temp_depth) <- "temp_depth"
      temp_depth <- projectRaster(temp_depth, aea)
      chl_surface <- raster(unlayer_yr$chl_surface[td])
      crs(chl_surface) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(chl_surface) <- "chl_surface"
      chl_surface <- projectRaster(chl_surface, aea)
      o2_depth <- raster(unlayer_yr$o2_depth[td])
      crs(o2_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(o2_depth) <- "o2_depth"
      o2_depth <- projectRaster(o2_depth, aea)
      salinity_depth <- raster(unlayer_yr$salinity_depth[td])
      crs(salinity_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(salinity_depth) <- "salinity_depth"
      salinity_depth <- projectRaster(salinity_depth, aea)
      nao_sample <- raster(unlayer_yr$nao_sample[td])
      crs(nao_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_sample) <- "nao_sample"
      nao_sample <- projectRaster(nao_sample, aea)
      nao_winter <- raster(unlayer_yr$nao_winter[td])
      crs(nao_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(nao_winter) <- "nao_winter"
      nao_winter <- projectRaster(nao_winter, aea)
      stackn <- unlayer_yr$stackname[td]
      stack <- stack(temp_depth, chl_surface, o2_depth, salinity_depth, nao_sample, nao_winter)
      #stackSave(test,unlayer_yr$stackname[td])
      pred <- predict(mod, stack, file = paste0("../output/maxent/predictions/", mth, "/", stackn, ".asc"), overwrite=TRUE, args='outputformat=cloglog') 
      prplot <- plot(pred, png(paste0("../output/maxent/predictions/", mth, "/", stackn, ".png"))) 
      dev.off() # stops automatic saving of the plot to a png
    }
}

stdep <- do.call(rbind, stackdeplst)
write.csv(stdep, paste0("../output/maxent/predictions/", mth, "/stack_depth.csv"), row.names = FALSE)
```

#model averageing

ok! now to average results:

- the AICforMaxentReg.csv 
- the maxentResults.csv
- the asc files per depth layer

open all maxentReg files

```{r avg maxentReg}
#mth <- "jan"
#modelmonth <- cbind(paste0(mth, unique(janprback$year)))
for (i in 1:length(modelmonth)){
  timeslice <- modelmonth[i]
  yr <- str_sub(timeslice, -4) #the year being used for testing
  if(yr == 2003){
    aic2003 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    } else if (yr == 2004){
    aic2004 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    } else if (yr == 2005){
    aic2005 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    } else if (yr == 2006){
    aic2006 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
  }
}

aic <- rbind(aic2003, aic2004, aic2005, aic2006)
aicm <- colMeans(aic)
aicm$mod <- "avg"
avgAIC <- rbind(aic, aicm)

write.csv(avgAIC, paste0("../output/maxent/models/", mth, "avgAIC.csv"), row.names = FALSE)
```

```{r avg maxres}
#mth <- "jan"
#modelmonth <- cbind(paste0(mth, unique(janprback$year)))
for (i in 1:length(modelmonth)){
  timeslice <- modelmonth[i]
  yr <- str_sub(timeslice, -4) #the year being used for testing
  if(yr == 2003){
    maxr2003 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2004){
    maxr2004 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2005){
    maxr2005 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2006){
    maxr2006 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
  }
}

maxr <- rbind(maxr2003, maxr2004, maxr2005, maxr2006)
maxr$Species <- 1
maxrm <- colMeans(maxr)
maxrm$Species <- "avg"
maxrm <- rbind(maxr, maxrm)

write.csv(maxrm, paste0("../output/maxent/models/", mth, "avgmaxentresults.csv"), row.names = FALSE)
```

for this bit may need to stack rasters by depth... this will need some working with the name
get unique filenames into a list
ignore the first X characters in the filename (yr_mth_) and stack based on the last bit of the filename
then do something probably with raster package

```{r avg asc layers}
asc_list <- list.files(paste0("../output/maxent/predictions/", mth), pattern = "*.asc", full.names = TRUE)
depthlayers <- data.frame(cbind(unique(stdep$ascdepths)))
names(depthlayers)[names(depthlayers) == "cbind.unique.stdep.ascdepths.."] <- "depth"
depthlayers$depth <- as.character(depthlayers$depth)

colno <- 1

for (d in 1:nrow(depthlayers)){
  dep <- depthlayers$depth[d]
  for (a in 1:length(asc_list)){
    asc <- asc_list[a]
    if (grepl(dep, asc)){
      depthlayers[d , paste0("a", colno)] <- asc
        colno <- colno+1
    }
  }
}
write.csv(depthlayers, (paste0("../output/maxent/predictions/", mth, "/asclayerbydepth.csv")), row.names = TRUE)


for (x in 1:nrow(depthlayers)){
  asclay <- depthlayers[x, ]
  asclay <- asclay[!is.na(asclay)]
  asclay <- as.data.frame(rbind(asclay))
  asclay$V1 <- as.character(asclay$V1)
  asclay$V2 <- as.character(asclay$V2)
  asclay$V3 <- as.character(asclay$V3)
  asclay$V4 <- as.character(asclay$V4)
  asclay$V5 <- as.character(asclay$V5)
  asclaydep <- asclay$V1
  
  asc2003 <- raster(asclay$V2)
  asc2004 <- raster(asclay$V3)
  asc2005 <- raster(asclay$V4)
  asc2006 <- raster(asclay$V5)

  stkasc <- stack(asc2003, asc2004, asc2005, asc2006)
  avg <- calc(stkasc, fun = mean)
  
  writeRaster(avg, (paste0("../output/maxent/predictions/", mth, "/avg_", asclaydep, ".asc")), overwrite=TRUE, args='outputformat=cloglog')
  avgplot <- plot(avg, png(paste0("../output/maxent/predictions/", mth, "/avg_", asclaydep, ".png"))) 
  dev.off()
}


ascdepth_list <- list.files(paste0("../output/maxent/predictions/", mth), glob2rx(pattern = "avg_*.asc"), full.names = TRUE)


asc120  <- raster(paste0("../output/maxent/predictions/", mth, "/avg_120.asc"))
asc41.18 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_41.18.asc"))
asc1.55586 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_1.55586.asc"))
asc1045.85 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_1045.85.asc"))
asc108.03 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_108.03.asc"))
asc11.7737 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_11.7737.asc"))
asc1151.99 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_1151.99.asc"))
asc1265.86 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_1265.86.asc"))
asc13.991 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_13.991.asc"))
asc133.076 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_133.076.asc"))
asc1387.38 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_1387.38.asc"))
asc147.406 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_147.406.asc"))
asc16.5253 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_16.5253.asc"))
asc163.165 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_163.165.asc"))
asc180.55 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_180.55.asc"))
asc19.4298 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_19.4298.asc"))
asc199.79 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_199.79.asc"))
asc2.66768 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_2.66768.asc"))
asc22.7576 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_22.7576.asc"))
asc221.141 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_221.141.asc"))
asc244.891 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_244.891.asc"))
asc26.5583 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_26.5583.asc"))
asc271.356 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_271.356.asc"))
asc3.85628 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_3.85628.asc"))
asc30.8746 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_30.8746.asc"))
asc300.888 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_300.888.asc"))
asc333.863 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_333.863.asc"))
asc35.7402 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_35.7402.asc"))
asc370.689 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_370.689.asc"))
asc411.794 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_411.794.asc"))
asc457.626 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_457.626.asc"))
asc47.2119 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_47.2119.asc"))
asc5.14036 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_5.14036.asc"))
asc508.64 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_508.64.asc"))
asc53.8506 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_53.8506.asc"))
asc565.292 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_565.292.asc"))
asc6.54303 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_6.54303.asc"))
asc61.1128 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_61.1128.asc"))
asc628.026 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_628.026.asc"))
asc69.0217 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_69.0217.asc"))
asc697.259 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_697.259.asc"))
asc77.6112 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_77.6112.asc"))
asc773.368 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_773.368.asc"))
asc8.09252 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_8.09252.asc"))
asc856.679 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_856.679.asc"))
asc86.9294 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_86.9294.asc"))
asc9.82275 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_9.82275.asc"))
asc947.448 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_947.448.asc"))
asc97.0413 <- raster(paste0("../output/maxent/predictions/", mth, "/avg_97.0413.asc"))

stackavg <- stack(asc120, asc41.18, asc1.55586, asc1045.85, asc108.03, asc11.7737, asc1151.99, asc1265.86, asc13.991, asc133.076, asc1387.38, asc147.406, asc16.5253, asc163.165, asc180.55, asc19.4298, asc199.79, asc2.66768, asc22.7576, asc221.141, asc244.891, asc26.5583, asc271.356, asc3.85628, asc30.8746, asc300.888, asc333.863, asc35.7402, asc370.689, asc411.794, asc457.626, asc47.2119, asc5.14036, asc508.64, asc53.8506, asc565.292, asc6.54303, asc61.1128, asc628.026, asc69.0217, asc697.259, asc77.6112, asc773.368, asc8.09252, asc856.679, asc86.9294, asc9.82275, asc947.448, asc97.0413)

sum <- calc(stkasc, fun = sum)
avg <- calc(stkasc, fun = mean)
  writeRaster(avg, (paste0("../output/maxent/predictions/", mth, "/avg_", mth, ".asc")), overwrite=TRUE)
  avgplot <- plot(avg, png(paste0("../output/maxent/predictions/", mth, "/avg_", mth, ".png"))) 
  dev.off()

```









asc120
asc41.18
asc1.55586
asc1045.85
asc108.03
asc11.7737
asc1151.99
asc1265.86
asc13.991
asc133.076
asc1387.38
asc147.406
asc16.5253
asc163.165
asc180.55
asc19.4298
asc199.79
asc2.66768
asc22.7576
asc221.141
asc244.891
asc26.5583
asc271.356
asc3.85628
asc30.8746
asc300.888
asc333.863
asc35.7402
asc370.689
asc411.794
asc457.626
asc47.2119
asc5.14036
asc508.64
asc53.8506
asc565.292
asc6.54303
asc61.1128
asc628.026
asc69.0217
asc697.259
asc77.6112
asc773.368
asc8.09252
asc856.679
asc86.9294
asc9.82275
asc947.448
asc97.0413


