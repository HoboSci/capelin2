---
title: "maxent model avec xvalidation (year-based test training)"
author: "Samantha Andrews"
output: html_notebook
---

# Overview
A note to anyone who might happen to stumble across this... I am a beginner in R and have had no exposure to similar languages. I don't know what I'm doing. The code herein is unlikely to be elegant and there area probably more efficient ways of running the code.

Built with 'r getRversion()'..

# Package dependencies
You can install and load them using the following code which uses a function called [ipak](https://gist.github.com/stevenworthington/3178163). Note this function checks to see if the packages are installed first before loading.


```{r pre-install & load packages, include=FALSE}
options(java.parameters = "-Xmx2g" )#needs to run before dismo loaded - boosts memory for java to 1g
packages <- c("dismo", "stringr", "rJava", "raster", "ecospat", "bossMaps", "lattice", "tidyr", "enmSdm")
source("../src/ipak.R")
ipak(packages)
```


#load the presence-background dataset 
("../output/bio/presab_nafo_yr.csv")

```{r load pres-background dataset}
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)
colnames(presback)
```

this dataset contains a lot of columns you don't need for the maxent models. Remove them here

```{r remove unnecessary columns}
presback <- subset(presback, select = -c(cell_id, id, decimalLatitude, decimalLongitude, datecollected, institutioncode, individualcount, depth, resname, originalscientificname, collectioncode, day, nafo_zone, gear, longitude_meters, latitude_meters, total_cell_obs_xy, total_cell_obs_xyt, bottom_depth, XXtotal_cell_obs_xyzt, temp_celsius_depth, temp_celsius_surface, longitude_meters.1, latitude_meters.1, bottom_depth_glorys, longitude_meters.2, latitude_meters.2, cell_id_3d, total_cell_obs_xyzt, cell_id_xyzt))
colnames(presback)
```

#monthly model data selection and prep
For each monthly model, subset the data to the month you want, and the variables you want (Based on spearmans and VIF)

```{r}
janvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_winter")
marvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
aprvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
mayvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
junvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
julvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
augvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
sepvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
octvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
novvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
decvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")

mthnavar_lst <- list(jan = janvar, mar = marvar, apr = aprvar, may = mayvar, jun = junvar, jul = julvar, aug = augvar, sep = sepvar, oct = octvar, nov = novvar, dec = decvar)
```

select month
```{r month of interest -change}
mthna <- "dec"
mthno <- "12"
```



```{r subsest data by month}
prback <- subset(presback, month == mthno)
prback <- subset(prback, select = mthnavar_lst[[mthna]])
```

now each month contains NAs - lets remove these (maxent principle doesnt allow for missing data - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.5607&rep=rep1&type=pdf)

note will need to reajust background points too as some years may no longer have presence data

```{r remove na vals}
prback <- na.omit(prback)
presyrs <-  subset(prback, occurrence == 1) #this is to get years with complete presence data 
presyrs <- unique(presyrs$year) #make a vector of unique years
prback <- prback[prback$year %in% presyrs, ] #keep only the data for which there is precence years

```


normal model..
mod12 <- maxent(x = prab, p = pa, file = .asc, args=c("maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE")) 
mod12

#```{r train and test inc AIC for reg val}
presyrs <-  #this is to get years with complete presence data 
  

modelmonth <- cbind(paste0(mthna ,unique(prback$year)))
aicetc <- read.csv("../data/env/AICcCalculations.csv", header = TRUE) #pre-created csv file
betavallist <- cbind(aicetc$regularization)

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(prback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  
  for (h in 1:nrow(betavallist)){
    betaval <-  betavallist[h]
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/", timeslice), args=c('plots=FALSE', "maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betavallist[h])))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2])) #dodgy 
    bic <- (bick*log(sum(trainpa == 1)) - 2*11) #dodgy
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
   #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
    for (i in 1:nrow(aicetc)){
    if(aicetc$regularization[i] == betaval){
      aicetc$train_AUC[i] <- trainauc
      aicetc$no_trainng_points[i] <- notrainingpoints
      aicetc$coefficients[i] <- nocoeff
      aicetc$sum.of.logs[i] <- sumsamplepred
      aicetc$test_AUC[i] <- evauc
      aicetc$test_evcor[i] <- evcor
      aicetc$test_evpcor[i] <- evpcor
      aicetc$test_nopresence[i] <- evnp
      aicetc$test_nobackground[i] <- evna
      aicetc$test_maxsumsenspec[i] <- evmaxtprtnr
      aicetc$test_maxkap[i] <- evmaxkap
      aicetc$test_no_omission[i] <- evno_omission
      aicetc$test_prevalence[i] <- evprevalence
      aicetc$test_equal_sens_spec[i] <- evequal_sens_spec
      aicetc$test_sensitivity[i] <- evsensitivity
      aicetc$test_bic[i] <- bic #not sure this is correct...
      aicetc$beta[i] <- betaval
      #calculate minimal predicted area using ecospat
      aicetc$mpa_0.9_cum[i] <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
      
    aicetc$AIC[i] <- ((2*aicetc$coefficients[i])-(2*aicetc$sum.of.logs[i]))
    aicetc$AICc[i] <- (-2*(aicetc$sum.of.logs[i])+((2*aicetc$coefficients[i])*(aicetc$no_trainng_points[i]/(aicetc$no_trainng_points[i] - aicetc$coefficients[i]-1))))
    }
   }
  }
  

write.csv(aicetc, paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)

}  
  

#```

#model selection
next step... select the models you want for each year and run those models again (primarily based on lowest AICc but check test AUC and other things too)

you need to go through each aic file manually....



KEEP A NOTE OF THESE IN ONENOTE

#run final model
```{r final models plus predict}
modelmonth <- cbind(paste0(mthna, unique(prback$year)))
aicetc <- read.csv("../data/env/AICcFinalmod.csv", header = TRUE) #pre-created csv file
unlayer <- read.csv(paste0("../data/env/asc_layerlist", mthna, ".csv"), header = TRUE) #if code doesnt work put back to unlayer_yr

for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(prback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  #mess_pr <- subset(train, occurrence == 1)
  #mess_pr  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling

  
  if (yr == "1998"){
    betaval <- 0.25
  } else if (yr == "2001"){
    betaval <- 0.75
  } else if (yr == "2002" | yr == "2003"| yr == "2004"| yr == "2006"| yr == "2011"){
    betaval <- 1
  } else if (yr == "2005"){
    betaval <- 1.25
  } else if (yr == "1999" | yr == "2000"| yr == "2009"){
    betaval <- 1.5
  } else if (yr == "2007"){
    betaval <- 1.75
  } else if (yr == "2010"){
    betaval <- 2
  } else if (yr == "2008"){
    betaval <- 2.25
  }

  
  
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/", timeslice), args=c("writebackgroundpredictions=TRUE",  "maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betaval)))

    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2]))
    bic <- (bick*log(sum(trainpa == 1)) - 2*11)
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
    #continuous boyce index
    predPres <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    predBg <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_backgroundPredictions.csv"), header = TRUE)
    predPres <- predPres$Cloglog.prediction
    predBg <- predBg$Cloglog
    cbi <- contBoyce(pres = predPres, bg = predBg)
    
  
      aicetc$train_AUC <- trainauc #training only AUC - not tested
      aicetc$no_trainng_points <- notrainingpoints #numberof points used for training
      aicetc$coefficients <- nocoeff #this is to calculate the AIC
      aicetc$sum.of.logs <- sumsamplepred #this is to calculate the AIC
      aicetc$test_AUC <- evauc #testing AUC
      aicetc$test_evcor <- evcor #testing correlation coefficient
      aicetc$test_evpcor <- evpcor # testing p-value for correlation coefficient
      aicetc$test_nopresence <- evnp 
      aicetc$test_nobackground <- evna
      aicetc$test_maxsumsenspec <- evmaxtprtnr
      aicetc$test_maxkap <- evmaxkap
      aicetc$test_no_omission <- evno_omission
      aicetc$test_prevalence <- evprevalence
      aicetc$test_equal_sens_spec <- evequal_sens_spec
      aicetc$test_sensitivity <- evsensitivity
      aicetc$tss <- max(ev@TPR + ev@TNR) - 1
      aicetc$test_bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      aicetc$cbi <- cbi
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$no_trainng_points/(aicetc$no_trainng_points - aicetc$coefficients-1))))
    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
    aicetc$mpa_0.9_clog <- ecospat.mpa(samplepred$Cloglog.prediction, perc = 0.9) #90%
    aicetc$year <- yr


    write.csv(aicetc, paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)


    unlayer_yr <- subset(unlayer, ascyears == yr)
    unlayer_yr <- unlayer_yr[-c(1), ]
    unlayer_yr[] <- lapply(unlayer_yr, as.character) #from https://stackoverflow.com/questions/2851015/convert-data-frame-columns-from-factors-to-characters
    stackdeplst <- list()
    stackdep <- subset(unlayer_yr, select = c(stackname, ascdepths))
    stackdeplst[[year]] <- stackdep
    write.csv(stackdep, paste0("../output/maxent/models/", timeslice, "/stackdepthlist_", yr, ".csv"), row.names = FALSE)
    aea <- raster("../output/env/aea.tif") 

   for (td in 1:nrow(unlayer_yr)){
      temp_depth <- raster(unlayer_yr$temp_depth[td])
      crs(temp_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(temp_depth) <- "temp_depth"
      temp_depth <- projectRaster(temp_depth, aea)
      chl_surface <- raster(unlayer_yr$chl_surface[td])
      crs(chl_surface) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(chl_surface) <- "chl_surface"
      chl_surface <- projectRaster(chl_surface, aea)
      o2_depth <- raster(unlayer_yr$o2_depth[td])
      crs(o2_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(o2_depth) <- "o2_depth"
      o2_depth <- projectRaster(o2_depth, aea)
      salinity_depth <- raster(unlayer_yr$salinity_depth[td])
      crs(salinity_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(salinity_depth) <- "salinity_depth"
      salinity_depth <- projectRaster(salinity_depth, aea)
      nao_sample <- raster(unlayer_yr$nao_sample[td])
      crs(nao_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_sample) <- "nao_sample"
      nao_sample <- projectRaster(nao_sample, aea)
      nao_prev <- raster(unlayer_yr$nao_prev[td])
      crs(nao_prev) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_prev) <- "nao_prev"
      nao_prev <- projectRaster(nao_prev, aea)
      nao_winter <- raster(unlayer_yr$nao_winter[td])
      crs(nao_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(nao_winter) <- "nao_winter"
      nao_winter <- projectRaster(nao_winter, aea)
      amo_sample <- raster(unlayer_yr$amo_sample[td])
      crs(amo_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(amo_sample) <- "amo_sample"
      amo_sample <- projectRaster(amo_sample, aea)
      amo_winter <- raster(unlayer_yr$amo_winter[td])
      crs(amo_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(amo_winter) <- "amo_winter"
      amo_winter <- projectRaster(amo_winter, aea)
      stackn <- unlayer_yr$stackname[td]
      stack <- stack(temp_depth, salinity_depth, o2_depth, chl_surface, nao_sample, nao_prev, nao_winter, amo_sample, amo_winter)


      #stackSave(test,unlayer_yr$stackname[td])
      pred <- predict(mod, stack, file = paste0("../output/maxent/predictions/", mthna, "/", "cloglog_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=cloglog')) 
      predraw <- predict(mod, stack, file = paste0("../output/maxent/predictions/", mthna, "/", "raw_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=raw')) 
      prplot <- plot(pred, png(paste0("../output/maxent/predictions/", mthna, "/", "cloglog_", stackn, ".png")))
      dev.off() # stops automatic saving of the plot to a png
     
      #mess
      
      #messev <- dismo::mess(x = stack, v = mess_pr, full = FALSE)
      #messplot <- plot(messev, png(paste0("../output/maxent/predictions/", mthna, "/", "mess_", stackn, ".png")))
      #dev.off()
      # not working how i'd like....
    }
}

stdep <- do.call(rbind, stackdeplst)
write.csv(stdep, paste0("../output/maxent/models/", timeslice, "/stack_depth.csv"), row.names = FALSE)
```

```{r avg maxentReg}

for (i in 1:length(modelmonth)){
  timeslice <- modelmonth[i]
  yr <- str_sub(timeslice, -4) #the year being used for testing
  if(yr == 1998){
    aic1998 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr1998 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 1999){
    aic1999 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr1999 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2000){
    aic2000 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2000 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2001){
    aic2001 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2001 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2002){
    aic2002 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2002 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2003){
    aic2003 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2003 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2004){
    aic2004 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2004 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2005){
    aic2005 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2005 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2006){
    aic2006 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2006 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2007){
    aic2007 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2007 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2008){
    aic2008 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2008 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2009){
    aic2009 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2009 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2010){
    aic2010 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2010 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2011){
    aic2011 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2011 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2012){
    aic2012 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2012 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2013){
    aic2013 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2013 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2014){
    aic2014 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2014 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    } else if (yr == 2015){
    aic2015 <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
    maxr2015 <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
  }
}

aic <- rbind(aic1998, aic1999, aic2000, aic2001, aic2002, aic2003, aic2004, aic2005, aic2006, aic2007, aic2008, aic2009, aic2010, aic2011)
maxr <- rbind(maxr1998, maxr1999, maxr2000, maxr2001, maxr2002, maxr2003, maxr2004, maxr2005, maxr2006, maxr2007, maxr2008, maxr2009, maxr2010, maxr2011)


aicm <- colMeans(aic)
aicm$mod <- "avg"
avgAIC <- rbind(aic, aicm)

maxr$Species <- 1
maxrm <- colMeans(maxr)
maxrm$Species <- "avg"
maxrm <- rbind(maxr, maxrm)

write.csv(avgAIC, paste0("../output/maxent/models/", mthna, "avgAIC.csv"), row.names = FALSE)
write.csv(maxrm, paste0("../output/maxent/models/", mthna, "avgmaxentresults.csv"), row.names = FALSE)
```

#binary maps - individual year layers

there seem to be two primary ways to create binary maps. the most common for conservation purposes seems to be to use maxsumspensspec values, however MPA also comes recommended (but is def less common). 

the thresholds are in the monthavgAIC.csv file in the model folder (not model/month)

```{r set up threshold binary function}
binmpa <- function(x) {
  ifelse(x <  mpa_thr, 0,
  ifelse(x >=  mpa_thr, 1, NA))
  }
```


```{r binary maps on individual layers cloglog}
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)

for (modtime in 1:nrow(modelmonth)){
  timeslice <- modelmonth[modtime]
  print(timeslice)
  yr <- str_sub(timeslice, -4)
  thresholds <- read.csv(paste0("../output/maxent/models/", timeslice, "/AICforMaxentReg.csv"), header = TRUE)
  mpa_thr <- thresholds$mpa_0.9_clog
  for (cum in 1:length(clogasc_list)){
    cumascyr <- str_sub(clogasc_list[cum], start = 44, end = 47) #selects the year from the file name
    if(yr == cumascyr){
      cumasc <- raster(clogasc_list[cum])
      ascname <- names(cumasc)
      cum_mpathr <- calc(cumasc, fun = binmpa)
      writeRaster(cum_mpathr, paste0("../output/maxent/predictions/", mthna,  "/binary_", ascname, ".asc"), overwrite = TRUE)
      plot(cum_mpathr, png(paste0("../output/maxent/predictions/", mthna, "/binary_", ascname, ".png")), overwrite = TRUE)
      dev.off() # stops automatic saving of the plot to a png
    }
  }
}
```

now for each year create a 2-d representation of suitable habitat

need to stack the rasters by year
run cellStats (sum)
save the output as they year

```{r binary map per year 2D representation}
binaryclog_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_cloglog.*.asc", full.names = TRUE)
yrlayer <- data.frame(matrix(ncol = 2, nrow = length(binaryclog_list)))
colnames(yrlayer) <- c("layer", "year")

for (yrlyr in 1:length(binaryclog_list)){
  yearoflyr <- str_sub(binaryclog_list[yrlyr], start = 51, end = 54) #selects the year from the file name
  yrlayer$year[yrlyr] <- yearoflyr
  yrlayer$layer[yrlyr] <- binaryclog_list[yrlyr]
}

y_list <- split(yrlayer, yrlayer$year)
noyrs <- unique(yrlayer$year)

for (binyr in (1:length(y_list))){
  binstack <- stack(y_list[[binyr]]$layer)
  year <- y_list[[binyr]]$year[1]
  stacksum <- sum(binstack, na.rm = TRUE)
  writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_2d_", year, ".asc"), overwrite=TRUE)
  plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_2d_", year, ".png")))
  dev.off()
}
  
```




#using averageing

ok! now to average results:

- the AICforMaxentReg.csv 
- the maxentResults.csv
- the asc files per depth layer

open all maxentReg files



for this bit may need to stack rasters by depth... this will need some working with the name
get unique filenames into a list
ignore the first X characters in the filename (yr_mthna_) and stack based on the last bit of the filename
then do something probably with raster package

```{r avg asc layers cloglog}
clogasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^cloglog_.*.asc", full.names = TRUE)
stdep <- read.csv(paste0("../output/maxent/models/", timeslice, "/stack_depth.csv"), header = TRUE)
depthlayers <- data.frame(cbind(unique(stdep$ascdepths)))
names(depthlayers)[names(depthlayers) == "cbind.unique.stdep.ascdepths.."] <- "depth"
depthlayers$depth <- as.character(depthlayers$depth)

colno <- 1

for (d in 1:nrow(depthlayers)){
  dep <- depthlayers$depth[d]
  for (a in 1:length(clogasc_list)){
    asc <- clogasc_list[a]
    if (grepl(dep, asc)){
      depthlayers[d , paste0("a", colno)] <- asc
        colno <- colno+1
    }
  }
}
write.csv(depthlayers, (paste0("../output/maxent/predictions/", mthna, "/cloglog_asclayerbydepth.csv")), row.names = TRUE)



for (x in 1:nrow(depthlayers)){
  asclay <- depthlayers[x, ]
  asclay <- asclay[!is.na(asclay)]
  asclay <- as.data.frame(rbind(asclay))
  asclay$V1 <- as.character(asclay$V1) #v1 corresponds to depth
  asclay$V2 <- as.character(asclay$V2) #v2 to end corresponds to year
  asclay$V3 <- as.character(asclay$V3)
  asclay$V4 <- as.character(asclay$V4)
  asclay$V5 <- as.character(asclay$V5)
  asclay$V6 <- as.character(asclay$V6)
  asclay$V7 <- as.character(asclay$V7)
  asclay$V8 <- as.character(asclay$V8)
  asclay$V9 <- as.character(asclay$V9)
  asclay$V10 <- as.character(asclay$V10)
  asclay$V11 <- as.character(asclay$V11)
  asclay$V12 <- as.character(asclay$V12)
  asclay$V13 <- as.character(asclay$V13)
  asclay$V14 <- as.character(asclay$V14)
  asclay$V15 <- as.character(asclay$V15)  


  
  asclaydep <- asclay$V1
  
  asc1998 <- raster(asclay$V2)
  asc1999 <- raster(asclay$V3)
  asc2000 <- raster(asclay$V4)
  asc2001 <- raster(asclay$V5)
  asc2002 <- raster(asclay$V6)
  asc2003 <- raster(asclay$V7)
  asc2004 <- raster(asclay$V8)
  asc2005 <- raster(asclay$V9)
  asc2006 <- raster(asclay$V10)
  asc2007 <- raster(asclay$V11)
  asc2008 <- raster(asclay$V12)
  asc2009 <- raster(asclay$V13)
  asc2010 <- raster(asclay$V14)
  asc2011 <- raster(asclay$V15)


  stkasc <- stack(asc1998, asc1999, asc2000, asc2001, asc2002, asc2003, asc2004, asc2005, asc2006, asc2007, asc2008, asc2009, asc2010, asc2011)

  avg <- mean(stkasc, na.rm = TRUE)
  
  writeRaster(avg, paste0("../output/maxent/predictions/", mthna, "/avg_cloglog_", asclaydep, ".asc"), overwrite=TRUE)
  avgplot <- plot(avg, png(paste0("../output/maxent/predictions/", mthna, "/avg_cloglog_", asclaydep, ".png"))) 
  dev.off()
}
```




```{r binary maps on averaged depth layer}
avgasc_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^avg_cloglog_.*.asc", full.names = TRUE)
thresholds <- read.csv(paste0("../output/maxent/models/", mthna, "avgAIC.csv"), header = TRUE)
thresholds <- tail(thresholds, 1) #subset the last row
mpa_thr <- thresholds$mpa_0.9_clog

for (avg in 1:length(avgasc_list)){
    cumasc <- raster(avgasc_list[avg])
    ascname <- names(cumasc)
    mpathr <- calc(cumasc, fun = binmpa)
    mpa_plot <- plot(mpathr, png(paste0("../output/maxent/predictions/", mthna, "/binary_", ascname, ".png")))
    dev.off() # stops automatic saving of the plot to a png
    writeRaster(mpathr, paste0("../output/maxent/predictions/", mthna, "/binary_", ascname, ".asc"), overwrite = TRUE)
}

```

```{r binary map averaged 2D representation}
binaryclog_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_cloglog.*.asc", full.names = TRUE)

binstack <- stack(binaryclog_list)
stacksum <- sum(binstack, na.rm = TRUE)
writeRaster(stacksum, paste0("../output/maxent/predictions/", mthna, "/binary_avg_2d.asc"), overwrite=TRUE)
plot(stacksum, png(paste0("../output/maxent/predictions/", mthna, "/binary_avg_2d.png")))
dev.off()

```


#plots by depth

first need some statistcs... for each layer how many cells have a value of 1...

```{r calc no presence cells per layer (avg)} 
ascdepth_list <- list.files(paste0("../output/maxent/predictions/", mthna), pattern = "^binary_avg_cloglog.*asc", full.names = TRUE)
binaryavgstack <- stack(ascdepth_list)
stackstat <- data.frame(matrix(ncol = 2, nrow = nlayers(binaryavgstack)))
stackstat[ ,1] <- c(1:49)
colnames(stackstat) <- c("layer", "cell_sum")

for (lyr in 1:nlayers(binaryavgstack)){
  lyrsum <- cellStats(binaryavgstack[[lyr]], sum)
  stackstat$cell_sum[lyr] <- lyrsum
}

write.csv(stackstat, paste0("../output/maxent/predictions/", mthna, "/cellcount_bydepth_avg.csv"), row.names = FALSE)
```


a crude plot but ok to show slr

```{r graph by depth (avg)}
bydepth <- barchart(layer ~ cell_sum, data = stackstat, ylim = c(49, 1))
trellis.device(device="png", filename = paste0("../output/maxent/predictions/", mthna, "/depthplot_avg.png"))
print(bydepth)
dev.off()
```



