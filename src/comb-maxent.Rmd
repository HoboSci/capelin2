  
```{r pre-install & load packages, include=FALSE}
options(java.parameters = "-Xmx2g" )#needs to run before dismo loaded - boosts memory for java to 1g
packages <- c("dismo", "stringr", "rJava", "raster", "ecospat", "bossMaps", "lattice", "tidyr", "enmSdm", "ggplot2", "plyr", "reshape2")
source("../src/ipak.R")
ipak(packages)
```

load the presence-background dataset 
("../output/bio/presab_nafo_yr.csv")

select month
```{r month of interest -change}
mthna <- "dec"
mthno <- "12"
```

```{r load pres-background dataset}
presback <- read.csv("../output/bio/presab_nafo_yr.csv", header = TRUE)
colnames(presback)
```

remove all rows with the year 2015 (due to low number of samples)
```{r}
presback <- subset(presback, year!="2015")
```


this dataset contains a lot of columns you don't need for the maxent models. Remove them here

```{r remove unnecessary columns}
presback <- subset(presback, select = -c(cell_id, id, decimalLatitude, decimalLongitude, datecollected, institutioncode, individualcount, depth, resname, originalscientificname, collectioncode, day, nafo_zone, gear, longitude_meters, latitude_meters, total_cell_obs_xy, total_cell_obs_xyt, bottom_depth, XXtotal_cell_obs_xyzt, temp_celsius_depth, temp_celsius_surface, longitude_meters.1, latitude_meters.1, bottom_depth_glorys, longitude_meters.2, latitude_meters.2, cell_id_3d, total_cell_obs_xyzt, cell_id_xyzt))
colnames(presback)
```

monthly model data selection and prep
For each monthly model, subset the data to the month you want, and the variables you want (Based on spearmans and VIF)

```{r}
marvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
aprvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
mayvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
junvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
julvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
augvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
sepvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
octvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
novvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")
decvar <- c("occurrence", "year", "temp_depth", "salinity_depth", "o2_depth", "chl_surface", "nao_sample", "nao_prev", "nao_winter", "amo_sample", "amo_winter")

mthnavar_lst <- list(mar = marvar, apr = aprvar, may = mayvar, jun = junvar, jul = julvar, aug = augvar, sep = sepvar, oct = octvar, nov = novvar, dec = decvar)
```

```{r subsest data by month}
prback <- subset(presback, month == mthno)
prback <- subset(prback, select = mthnavar_lst[[mthna]])
```

now each month contains NAs - lets remove these (maxent principle doesnt allow for missing data - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.5607&rep=rep1&type=pdf)

note will need to reajust background points too as some years may no longer have presence data

```{r remove na vals}
prback <- na.omit(prback)
presyrs <-  subset(prback, occurrence == 1) #this is to get years with complete presence data 
presyrs <- unique(presyrs$year) #make a vector of unique years
prback <- prback[prback$year %in% presyrs, ] #keep only the data for which there is precence years

```



```{r final models plus predict}
modelmonth <- cbind(paste0(mthna, unique(prback$year)))
aicetc <- read.csv("../data/env/AICcFinalmod.csv", header = TRUE) #pre-created csv file
unlayer <- read.csv(paste0("../data/env/test-comb/asc_layerlist", mthna, ".csv"), header = TRUE) #if code doesnt work put back to unlayer_yr



for (year in 1:nrow(modelmonth)){
  timeslice <- modelmonth[year] #testing timeslice
  yr <- str_sub(timeslice, -4) #the year being used for testing
  train <- subset(prback, year != yr) #training data is all years but testing
  trainpa <- train$occurrence #creates a vector of presence/background ID (1/0)
  test <-  subset(prback, year == yr) #creates the testing dataset
  testp <- subset(test, occurrence == "1") #splits the testing dataset into presences
  testp <- subset(testp, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  testb <- subset(test, occurrence == "0") #splits the testing dataset into background
  testb <- subset(testb, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  #mess_pr <- subset(train, occurrence == 1)
  #mess_pr  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling
  train  <- subset(train, select = -c(year, occurrence)) #don't need year and occurrence for modelling

  
  if (yr == "1998"){
    betaval <- 0.25
  } else if (yr == "2001"){
    betaval <- 0.75
  } else if (yr == "2002" | yr == "2003"| yr == "2004"| yr == "2006"| yr == "2011"){
    betaval <- 1
  } else if (yr == "2005"){
    betaval <- 1.25
  } else if (yr == "1999" | yr == "2000"| yr == "2009"){
    betaval <- 1.5
  } else if (yr == "2007"){
    betaval <- 1.75
  } else if (yr == "2010"){
    betaval <- 2
  } else if (yr == "2008"){
    betaval <- 2.25
  }


  
  
    mod <- maxent(x = train, p = trainpa, path = paste0("../output/maxent/models/test-comb/", timeslice), args=c("writebackgroundpredictions=TRUE",  "maximumiterations=5000", "responsecurves=TRUE", "jackknife=TRUE", "threads=8", "addsamplestobackground=TRUE", paste0("betamultiplier=", betaval)))
    
    saveRDS(mod, file= paste0("../output/maxent/models/test-comb/", timeslice, "/", timeslice, ".rda"))


    #now based on glover-kapfer pdf with excel manual + https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/10-1171.1... + adaptation for        getting testAUC.. horrible code

    #count number of non-zero coefficients, excluding the final four rows
    coefile <- read.csv(paste0("../output/maxent/models/", timeslice, "/species.lambdas"), header = FALSE, stringsAsFactors=FALSE)
    coefile <- head(coefile, -4)
    coefile2 <- subset(coefile, V2 > 0 | V2 < 0)
    nocoeff <- nrow(coefile2)
    bick <- sum(as.numeric(coefile2[, 2]))
    bic <- (bick*log(sum(trainpa == 1)) - 2*11)
    
    #no presences used in model (less those used for testing)
    maxresults <- read.csv(paste0("../output/maxent/models/", timeslice, "/maxentResults.csv"), header = TRUE)
    notrainingpoints <- maxresults$X.Training.samples
    testauc <- maxresults$Test.AUC
    trainauc <- maxresults$Training.AUC
    
    #natural log
    samplepred <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    samplepred$nat_log <- log(samplepred$Raw.prediction)
    sumsamplepred <- sum(samplepred$nat_log)
  
  
    #test auc scores and other lovely things you might want to include
    ev <- evaluate(p = testp, a= testb, model = mod)
    evauc <- ev@auc
    evcor <- ev@cor
    evpcor <- ev@pcor
    evnp <- ev@np
    evna <- ev@na
    evmaxtprtnr <- threshold(ev, 'spec_sens')
    evmaxkap <- threshold(ev, 'kappa')
    evno_omission <- threshold(ev, 'no_omission')
    evprevalence <- threshold(ev, 'prevalence')
    evequal_sens_spec <- threshold(ev, 'equal_sens_spec')
    evsensitivity <- threshold(ev, 'sensitivity')
    
    #continuous boyce index
    predPres <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_samplePredictions.csv"), header = TRUE)
    predBg <- read.csv(paste0("../output/maxent/models/", timeslice, "/species_backgroundPredictions.csv"), header = TRUE)
    predPres <- predPres$Cloglog.prediction
    predBg <- predBg$Cloglog
    source("../src/contBoyce.R")
    cbi <- contBoyce(pres = predPres, bg = predBg)
    
  
      aicetc$train_AUC <- trainauc #training only AUC - not tested
      aicetc$no_trainng_points <- notrainingpoints #numberof points used for training
      aicetc$coefficients <- nocoeff #this is to calculate the AIC
      aicetc$sum.of.logs <- sumsamplepred #this is to calculate the AIC
      aicetc$test_AUC <- evauc #testing AUC
      aicetc$test_evcor <- evcor #testing correlation coefficient
      aicetc$test_evpcor <- evpcor # testing p-value for correlation coefficient
      aicetc$test_nopresence <- evnp 
      aicetc$test_nobackground <- evna
      aicetc$test_maxsumsenspec <- evmaxtprtnr
      aicetc$test_maxkap <- evmaxkap
      aicetc$test_no_omission <- evno_omission
      aicetc$test_prevalence <- evprevalence
      aicetc$test_equal_sens_spec <- evequal_sens_spec
      aicetc$test_sensitivity <- evsensitivity
      aicetc$tss <- max(ev@TPR + ev@TNR) - 1
      aicetc$test_bic <- bic #not sure this is correct...
      aicetc$beta <- betaval
      aicetc$cbi <- cbi
      
    aicetc$AIC <- ((2*aicetc$coefficients)-(2*aicetc$sum.of.logs))
    aicetc$AICc <- (-2*(aicetc$sum.of.logs)+((2*aicetc$coefficients)*(aicetc$no_trainng_points/(aicetc$no_trainng_points - aicetc$coefficients-1))))
    
    #calculate minimal predicted area using ecospat
    aicetc$mpa_0.9_cum <- ecospat.mpa(samplepred$Cumulative.prediction, perc = 0.9) #90%
    aicetc$mpa_0.9_clog <- ecospat.mpa(samplepred$Cloglog.prediction, perc = 0.9) #90%
    aicetc$year <- yr


    write.csv(aicetc, paste0("../output/maxent/models/test-comb/", timeslice, "/AICforMaxentReg.csv"), row.names = FALSE)
    
    mod <- readRDS(paste0("../output/maxent/models/test-comb/", timeslice, "/", timeslice, ".rda"))


    yr <- as.numeric(yr)
 unlayer_yr <- subset(unlayer, ascyearslist == yr)
    #unlayer_yr <- unlayer_yr[-c(1), ]
    unlayer_yr[] <- lapply(unlayer_yr, as.character) #from https://stackoverflow.com/questions/2851015/convert-data-frame-columns-from-factors-to-characters
    stackdeplst <- list()
    stackdep <- subset(unlayer_yr, select = c(stackname))
    stackdeplst[[year]] <- stackdep
    write.csv(stackdep, paste0("../output/maxent/models/test-comb/", timeslice, "/stackdepthlist_", yr, ".csv"), row.names = FALSE)
    aea <- raster("../output/env/aea.tif") 

    
  for (td in 1:nrow(unlayer_yr)){
      temp_depth <- raster(unlayer_yr$temp_depth[td])
      crs(temp_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(temp_depth) <- "temp_depth"
      #temp_depth <- projectRaster(temp_depth, aea)
      chl_surface <- raster(unlayer_yr$chl_surface[td])
      crs(chl_surface) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(chl_surface) <- "chl_surface"
      #chl_depth <- projectRaster(chl_depth, aea)
      o2_depth <- raster(unlayer_yr$o2_depth[td])
      crs(o2_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(o2_depth) <- "o2_depth"
      #o2_depth <- projectRaster(o2_depth, aea)
      salinity_depth <- raster(unlayer_yr$salinity_depth[td])
      crs(salinity_depth) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(salinity_depth) <- "salinity_depth"
      #salinity_depth <- projectRaster(salinity_depth, aea)
      nao_sample <- raster(unlayer_yr$nao_sample[td])
      crs(nao_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_sample) <- "nao_sample"
      #nao_sample <- projectRaster(nao_sample, aea)
      nao_prev <- raster(unlayer_yr$nao_prev[td])
      crs(nao_prev) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(nao_prev) <- "nao_prev"
      #nao_prev <- projectRaster(nao_prev, aea)
      nao_winter <- raster(unlayer_yr$nao_winter[td])
      crs(nao_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(nao_winter) <- "nao_winter"
      #nao_winter <- projectRaster(nao_winter, aea)
      amo_sample <- raster(unlayer_yr$amo_sample[td])
      crs(amo_sample) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
      names(amo_sample) <- "amo_sample"
      #amo_sample <- projectRaster(amo_sample, aea)
      amo_winter <- raster(unlayer_yr$amo_winter[td])
      crs(amo_winter) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
      names(amo_winter) <- "amo_winter"
      #amo_winter <- projectRaster(amo_winter, aea)
      stackn <- unlayer_yr$stackname[td]
      stack <- stack(temp_depth, salinity_depth, o2_depth, chl_surface, nao_sample, nao_prev, nao_winter, amo_sample, amo_winter)


      #stackSave(test,unlayer_yr$stackname[td])
      pred <- predict(mod, stack, file = paste0("../output/maxent/predictions/test-comb/", mthna, "/", "cloglog_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=cloglog')) 
      # predraw <- predict(mod, stack, file = paste0("../output/maxent/predictions/test-comb/", mthna, "/", "raw_", stackn, ".asc"), overwrite=TRUE, args=c('outputformat=raw')) 
      prplot <- plot(pred, png(paste0("../output/maxent/predictions/test-comb/", mthna, "/", "cloglog_", stackn, ".png")))
      dev.off() # stops automatic saving of the plot to a png
  }
}
```

all layers need to be spit in bash

